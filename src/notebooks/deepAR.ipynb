{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try DeepAR\n",
    "* PytorchForecasting [Get Started](https://pytorch-forecasting.readthedocs.io/en/stable/getting-started.html)\n",
    "* DeepAR [doc](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.models.deepar.DeepAR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_forecasting import TimeSeriesDataSet, DeepAR\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Used Yujie's cleaned version\n",
    "DIR_BYID = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/local_data/content/databyid'\n",
    "\n",
    "ls_all_invest_ids = sorted([int(fn.split('.')[0]) for fn in os.listdir(os.path.join(DIR_BYID, 'target'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = [f\"f_{i}\" for i in range(300)]\n",
    "# Read a subset for testing\n",
    "n = 2\n",
    "ls_dfs = []\n",
    "for id in ls_all_invest_ids[:n]:\n",
    "    df_f_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'feats/{id}.npy')), columns=f_cols)\n",
    "    df_t_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'target/{id}.npy')), columns=['target'])\n",
    "    df_f_id['investment_id'] = id\n",
    "    df_f_id = df_f_id[['investment_id'] + f_cols] # reorder columns\n",
    "    ls_dfs.append(pd.concat([df_t_id, df_f_id], axis=1))\n",
    "\n",
    "df = pd.concat(ls_dfs).reset_index().rename(columns={'index': 'time_id'})\n",
    "df = df.sort_values(by=['time_id']) # sort by time before splitting\n",
    "\n",
    "# Use a few features for testing\n",
    "df = df.iloc[:, :6]\n",
    "f_cols = [c for c in df.columns if 'f_' in c]\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "df_train, df_val = train_test_split(df_train, test_size=2/9, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.300875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.917045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.373575</td>\n",
       "      <td>0.296349</td>\n",
       "      <td>0.019102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>851</td>\n",
       "      <td>0.215225</td>\n",
       "      <td>0</td>\n",
       "      <td>0.304855</td>\n",
       "      <td>-1.116719</td>\n",
       "      <td>0.286537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>-1.143757</td>\n",
       "      <td>0.051038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>-0.103114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>-1.143757</td>\n",
       "      <td>0.051038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>-0.784968</td>\n",
       "      <td>-0.026920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>853</td>\n",
       "      <td>0.625438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>-0.784968</td>\n",
       "      <td>-0.026920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1708 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_id    target  investment_id       f_0       f_1       f_2\n",
       "0           0  0.000000              0  0.000000  0.000000  0.000000\n",
       "1220        0 -0.300875              1  0.932573  0.113691 -0.402206\n",
       "1221        1 -0.917045              1  0.373575  0.296349  0.019102\n",
       "1           1  0.000000              0  0.000000  0.000000  0.000000\n",
       "2           2  0.000000              0  0.000000  0.000000  0.000000\n",
       "...       ...       ...            ...       ...       ...       ...\n",
       "851       851  0.215225              0  0.304855 -1.116719  0.286537\n",
       "2072      852  0.000000              1  0.023042 -1.143757  0.051038\n",
       "852       852 -0.103114              0  0.023042 -1.143757  0.051038\n",
       "2073      853  0.000000              1  0.125338 -0.784968 -0.026920\n",
       "853       853  0.625438              0  0.125338 -0.784968 -0.026920\n",
       "\n",
       "[1708 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders\n",
    "* Ref: https://pytorch-forecasting.readthedocs.io/en/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import NormalDistributionLoss\n",
    "\n",
    "# load data\n",
    "# define dataset\n",
    "max_encoder_length = 6\n",
    "max_prediction_length = 1\n",
    "\n",
    "# create validation and training dataset\n",
    "batch_size = 128\n",
    "max_prediction_length = 3\n",
    "max_encoder_length = 24\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    group_ids=[\"investment_id\"],\n",
    "    target=\"target\",\n",
    "    time_idx=\"time_id\",\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    # static_reals=[],\n",
    "    time_varying_known_reals=f_cols,\n",
    "    time_varying_unknown_reals=['target'], # Need this for DeepAR\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"investment_id\"], \n",
    "        # transformation=\"softplus\" # NOTE: do not use softplus or relu for encoder normalization with DeepAR\n",
    "    ),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet.from_dataset(train_dataset, df_val, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = val_dataset.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0) # Check this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sizes of x =\n",
      "\tencoder_cat = torch.Size([64, 24, 0])\n",
      "\tencoder_cont = torch.Size([64, 24, 8])\n",
      "\tencoder_target = torch.Size([64, 24])\n",
      "\tencoder_lengths = torch.Size([64])\n",
      "\tdecoder_cat = torch.Size([64, 3, 0])\n",
      "\tdecoder_cont = torch.Size([64, 3, 8])\n",
      "\tdecoder_target = torch.Size([64, 3])\n",
      "\tdecoder_lengths = torch.Size([64])\n",
      "\tdecoder_time_idx = torch.Size([64, 3])\n",
      "\tgroups = torch.Size([64, 1])\n",
      "\ttarget_scale = torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "# print(\"x =\", x)\n",
    "# print(\"\\ny =\", y)\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")\n",
    "\n",
    "# sizes of x =\n",
    "# \tencoder_cat = torch.Size([64, 24, 0])    # (B, encoder_len, in_categorical_feats)\n",
    "# \tencoder_cont = torch.Size([64, 24, 304]) # (B, encoder_len, in_continuous_feats)\n",
    "# \tencoder_target = torch.Size([64, 24])    # (B, encoder_len)\n",
    "# \tencoder_lengths = torch.Size([64])       # (B, )\n",
    "# \tdecoder_cat = torch.Size([64, 3, 0])     # (B, decoder_len, out_categorical_feats) \n",
    "# \tdecoder_cont = torch.Size([64, 3, 304])  # (B, decoder_len, out_continuous_feats)\n",
    "# \tdecoder_target = torch.Size([64, 3])     # (B, decoder_len)\n",
    "# \tdecoder_lengths = torch.Size([64])       # (B, )\n",
    "# \tdecoder_time_idx = torch.Size([64, 3])   # (B, decoder_len)\n",
    "# \tgroups = torch.Size([64, 1])             # (B, n_investment_id)\n",
    "# \ttarget_scale = torch.Size([64, 2])       # (B, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure DeepAR model (Han 2022-4-21 update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 52.4k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  99%|█████████▉| 99/100 [00:04<00:00, 20.89it/s]Restoring states from the checkpoint path at /media/user/12TB1/HanLi/GitHub/CMU11785-project/src/notebooks/.lr_find_0a7e0416-bad1-4d47-9b39-496e223818d6.ckpt\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:04<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 2.5118864315095805e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "model = DeepAR.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=64,  # most important hyperparameter apart from learning rate\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    # loss=NormalDistributionLoss(),\n",
    "    # # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {model.size()/1e3:.1f}k\")\n",
    "\n",
    "\n",
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model (Han 2022-4-21 update)\n",
    "\n",
    "* Note: use tensorboard to check the logs: run ```tensorboard --logdir=<logging_folder>```\n",
    "* To visualize tensorboard in Jupyter Notebook: \n",
    "    ```\n",
    "    %reload_ext tensorboard\n",
    "    %tensorboard --logdir=<logging_folder>\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtsbyq_wb\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/user/12TB1/HanLi/GitHub/CMU11785-project/src/notebooks/wandb/run-20220421_233410-38ddwysr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/11785_project/PyTorchForecasting_test/runs/38ddwysr\" target=\"_blank\">DeepAR_Test_421</a></strong> to <a href=\"https://wandb.ai/11785_project/PyTorchForecasting_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                   | Type                   | Params\n",
      "------------------------------------------------------------------\n",
      "0 | loss                   | NormalDistributionLoss | 0     \n",
      "1 | logging_metrics        | ModuleList             | 0     \n",
      "2 | embeddings             | MultiEmbedding         | 0     \n",
      "3 | rnn                    | LSTM                   | 52.2 K\n",
      "4 | distribution_projector | Linear                 | 130   \n",
      "------------------------------------------------------------------\n",
      "52.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.4 K    Total params\n",
      "0.209     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 52.4k\n",
      "Epoch 4:  52%|█████▏    | 14/27 [00:06<00:06,  2.11it/s, loss=-0.429, v_num=wysr, train_loss_step=0.931, val_loss=1.150, train_loss_epoch=0.132]"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "DIR_LOGS = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/logs' # Change this!\n",
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_SMAPE', \n",
    "    dirpath='/media/user/12TB1/HanLi/GitHub/CMU11785-project/logs/model_checkpoints/', \n",
    "    save_top_k=2, \n",
    "    filename='500-default-{epoch:02d}-{val_SMAPE:.2f}'\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    entity=\"11785_project\",\n",
    "    project=\"PyTorchForecasting_test\",\n",
    "    name='DeepAR_Test_421',\n",
    "    log_model=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    gpus=1,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback, checkpoint_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "model = DeepAR.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=64,  # most important hyperparameter apart from learning rate\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    # loss=NormalDistributionLoss(),\n",
    "    # # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {model.size()/1e3:.1f}k\")\n",
    "\n",
    "# fit network\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: test model and calculate performance metrics on test data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52c4a99fb36d68752ce25c6541fc636e9171dab977cfe863248a143161a3b436"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('11785_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
