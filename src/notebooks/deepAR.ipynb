{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try DeepAR\n",
    "* PytorchForecasting [Get Started](https://pytorch-forecasting.readthedocs.io/en/stable/getting-started.html)\n",
    "* DeepAR [doc](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.models.deepar.DeepAR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/11785_project/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_forecasting import TimeSeriesDataSet, DeepAR\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Used Yujie's cleaned version\n",
    "DIR_BYID = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/local_data/content/databyid'\n",
    "\n",
    "ls_all_invest_ids = sorted([int(fn.split('.')[0]) for fn in os.listdir(os.path.join(DIR_BYID, 'target'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = [f\"f_{i}\" for i in range(300)]\n",
    "# Read a subset for testing\n",
    "# n = 2\n",
    "ls_dfs = []\n",
    "# for id in ls_all_invest_ids[:n]:\n",
    "for id in ls_all_invest_ids:\n",
    "    df_f_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'feats/{id}.npy')), columns=f_cols)\n",
    "    df_t_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'target/{id}.npy')), columns=['target'])\n",
    "    df_f_id['investment_id'] = id\n",
    "    df_f_id = df_f_id[['investment_id'] + f_cols] # reorder columns\n",
    "    ls_dfs.append(pd.concat([df_t_id, df_f_id], axis=1))\n",
    "\n",
    "df = pd.concat(ls_dfs).reset_index().rename(columns={'index': 'time_id'})\n",
    "df = df.sort_values(by=['time_id']) # sort by time before splitting\n",
    "\n",
    "# # Use a few features for testing\n",
    "# df = df.iloc[:, :6]\n",
    "# f_cols = [c for c in df.columns if 'f_' in c]\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "df_train, df_val = train_test_split(df_train, test_size=2/9, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.300875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.917045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.373575</td>\n",
       "      <td>0.296349</td>\n",
       "      <td>0.019102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>851</td>\n",
       "      <td>0.215225</td>\n",
       "      <td>0</td>\n",
       "      <td>0.304855</td>\n",
       "      <td>-1.116719</td>\n",
       "      <td>0.286537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>-1.143757</td>\n",
       "      <td>0.051038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>-0.103114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>-1.143757</td>\n",
       "      <td>0.051038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>-0.784968</td>\n",
       "      <td>-0.026920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>853</td>\n",
       "      <td>0.625438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>-0.784968</td>\n",
       "      <td>-0.026920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1708 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_id    target  investment_id       f_0       f_1       f_2\n",
       "0           0  0.000000              0  0.000000  0.000000  0.000000\n",
       "1220        0 -0.300875              1  0.932573  0.113691 -0.402206\n",
       "1221        1 -0.917045              1  0.373575  0.296349  0.019102\n",
       "1           1  0.000000              0  0.000000  0.000000  0.000000\n",
       "2           2  0.000000              0  0.000000  0.000000  0.000000\n",
       "...       ...       ...            ...       ...       ...       ...\n",
       "851       851  0.215225              0  0.304855 -1.116719  0.286537\n",
       "2072      852  0.000000              1  0.023042 -1.143757  0.051038\n",
       "852       852 -0.103114              0  0.023042 -1.143757  0.051038\n",
       "2073      853  0.000000              1  0.125338 -0.784968 -0.026920\n",
       "853       853  0.625438              0  0.125338 -0.784968 -0.026920\n",
       "\n",
       "[1708 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders\n",
    "* Ref: https://pytorch-forecasting.readthedocs.io/en/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import NormalDistributionLoss\n",
    "\n",
    "# define dataset\n",
    "max_encoder_length = 6\n",
    "max_prediction_length = 1\n",
    "\n",
    "# create validation and training dataset\n",
    "batch_size = 128\n",
    "max_prediction_length = 3 # prediction horizon\n",
    "max_encoder_length = 24   # lookback steps\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    group_ids=[\"investment_id\"],\n",
    "    target=\"target\",\n",
    "    time_idx=\"time_id\",\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    # static_reals=[],\n",
    "    time_varying_known_reals=f_cols,\n",
    "    time_varying_unknown_reals=['target'], # Need this for DeepAR\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"investment_id\"], \n",
    "        # transformation=\"softplus\" # NOTE: do not use softplus or relu for encoder normalization with DeepAR\n",
    "    ),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet.from_dataset(train_dataset, df_val, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=32)\n",
    "val_dataloader = val_dataset.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sizes of x =\n",
      "\tencoder_cat = torch.Size([128, 24, 0])\n",
      "\tencoder_cont = torch.Size([128, 24, 8])\n",
      "\tencoder_target = torch.Size([128, 24])\n",
      "\tencoder_lengths = torch.Size([128])\n",
      "\tdecoder_cat = torch.Size([128, 3, 0])\n",
      "\tdecoder_cont = torch.Size([128, 3, 8])\n",
      "\tdecoder_target = torch.Size([128, 3])\n",
      "\tdecoder_lengths = torch.Size([128])\n",
      "\tdecoder_time_idx = torch.Size([128, 3])\n",
      "\tgroups = torch.Size([128, 1])\n",
      "\ttarget_scale = torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "# print(\"x =\", x)\n",
    "# print(\"\\ny =\", y)\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")\n",
    "\n",
    "# sizes of x =\n",
    "# \tencoder_cat = torch.Size([64, 24, 0])    # (B, encoder_len, in_categorical_feats)\n",
    "# \tencoder_cont = torch.Size([64, 24, 304]) # (B, encoder_len, in_continuous_feats)\n",
    "# \tencoder_target = torch.Size([64, 24])    # (B, encoder_len)\n",
    "# \tencoder_lengths = torch.Size([64])       # (B, )\n",
    "# \tdecoder_cat = torch.Size([64, 3, 0])     # (B, decoder_len, out_categorical_feats) \n",
    "# \tdecoder_cont = torch.Size([64, 3, 304])  # (B, decoder_len, out_continuous_feats)\n",
    "# \tdecoder_target = torch.Size([64, 3])     # (B, decoder_len)\n",
    "# \tdecoder_lengths = torch.Size([64])       # (B, )\n",
    "# \tdecoder_time_idx = torch.Size([64, 3])   # (B, decoder_len)\n",
    "# \tgroups = torch.Size([64, 1])             # (B, n_investment_id)\n",
    "# \ttarget_scale = torch.Size([64, 2])       # (B, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure DeepAR model (Han 2022-4-21 update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 52.4k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Finding best initial lr:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:15<00:05,  4.77it/s]\n",
      "LR finder stopped early after 76 steps due to diverging loss.\n",
      "Restoring states from the checkpoint path at /media/user/12TB1/HanLi/GitHub/CMU11785-project/src/notebooks/.lr_find_022e35a5-07e7-4098-92e2-e7698dbba487.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.17782794100389226\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "# pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "model = DeepAR.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=64,  # most important hyperparameter apart from learning rate\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    loss=NormalDistributionLoss(),\n",
    "    # # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {model.size()/1e3:.1f}k\")\n",
    "\n",
    "\n",
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model (Han 2022-4-21 update)\n",
    "\n",
    "* Note: use tensorboard to check the logs: run ```tensorboard --logdir=<logging_folder>```\n",
    "* To visualize tensorboard in Jupyter Notebook: \n",
    "    ```\n",
    "    %reload_ext tensorboard\n",
    "    %tensorboard --logdir=<logging_folder>\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtsbyq_wb\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/user/12TB1/HanLi/GitHub/CMU11785-project/src/notebooks/wandb/run-20220422_001330-2912xq4f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/11785_project/PyTorchForecasting_test/runs/2912xq4f\" target=\"_blank\">DeepAR_Test_421</a></strong> to <a href=\"https://wandb.ai/11785_project/PyTorchForecasting_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                   | Type                   | Params\n",
      "------------------------------------------------------------------\n",
      "0 | loss                   | NormalDistributionLoss | 0     \n",
      "1 | logging_metrics        | ModuleList             | 0     \n",
      "2 | embeddings             | MultiEmbedding         | 0     \n",
      "3 | rnn                    | LSTM                   | 1.3 M \n",
      "4 | distribution_projector | Linear                 | 514   \n",
      "------------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.302     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 1325.6k\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.36it/s, loss=0.85, v_num=xq4f, train_loss_step=0.00358, val_loss=1.350, train_loss_epoch=0.820]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f9e4a009550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/11785_project/lib/python3.9/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:27<00:00,  1.94s/it, loss=5.71, v_num=xq4f, train_loss_step=0.804, val_loss=1.340, train_loss_epoch=1.420]    "
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "DIR_LOGS = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/logs' # Change this!\n",
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_SMAPE', \n",
    "    dirpath='/media/user/12TB1/HanLi/GitHub/CMU11785-project/logs/model_checkpoints/', \n",
    "    save_top_k=2, \n",
    "    filename='500-default-{epoch:02d}-{val_SMAPE:.2f}'\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    entity=\"11785_project\",\n",
    "    project=\"project_runs\",\n",
    "    name='DeepAR_first_run',\n",
    "    log_model=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    gpus=1,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    # limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback, checkpoint_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "model = DeepAR.from_dataset(\n",
    "    train_dataset,\n",
    "    cell_type='LSTM',\n",
    "    rnn_layers=3,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=256,  # most important hyperparameter apart from learning rate\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    # loss=NormalDistributionLoss(),\n",
    "    # # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {model.size()/1e3:.1f}k\")\n",
    "\n",
    "# fit network\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: test model and calculate performance metrics on test data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52c4a99fb36d68752ce25c6541fc636e9171dab977cfe863248a143161a3b436"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('11785_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
