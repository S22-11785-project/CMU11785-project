{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try TemporalFusionTransformer\n",
    "* Read: https://towardsdatascience.com/temporal-fusion-transformer-a-primer-on-deep-forecasting-in-python-4eb37f3f3594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Used Yujie's cleaned version\n",
    "DIR_BYID = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/local_data/content/databyid'\n",
    "\n",
    "ls_all_invest_ids = sorted([int(fn.split('.')[0]) for fn in os.listdir(os.path.join(DIR_BYID, 'target'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = [f\"f_{i}\" for i in range(300)]\n",
    "# Read a subset for testing\n",
    "n = 3\n",
    "ls_dfs = []\n",
    "for id in ls_all_invest_ids[:n]:\n",
    "    df_f_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'feats/{id}.npy')), columns=f_cols)\n",
    "    df_t_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'target/{id}.npy')), columns=['target'])\n",
    "    df_f_id['investment_id'] = id\n",
    "    ls_dfs.append(pd.concat([df_t_id, df_f_id], axis=1))\n",
    "\n",
    "df = pd.concat(ls_dfs).reset_index().rename(columns={'index': 'time_id'})\n",
    "df = df.sort_values(by=['time_id']) # sort by time before splitting\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "# df_train, df_val = train_test_split(df_train, test_size=2/9, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "      <th>investment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.300875</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "      <td>0.378386</td>\n",
       "      <td>-0.203938</td>\n",
       "      <td>-0.413469</td>\n",
       "      <td>0.965623</td>\n",
       "      <td>1.230508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>0.200075</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.086764</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-1.044826</td>\n",
       "      <td>-0.287605</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.231040</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>-0.514115</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>-0.616673</td>\n",
       "      <td>-0.194255</td>\n",
       "      <td>1.771210</td>\n",
       "      <td>1.428127</td>\n",
       "      <td>1.134144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.734579</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.387617</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.929529</td>\n",
       "      <td>-0.974060</td>\n",
       "      <td>-0.343624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.917045</td>\n",
       "      <td>0.373575</td>\n",
       "      <td>0.296349</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>-0.031842</td>\n",
       "      <td>-0.222027</td>\n",
       "      <td>-0.199950</td>\n",
       "      <td>1.325165</td>\n",
       "      <td>1.267433</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.081652</td>\n",
       "      <td>0.645607</td>\n",
       "      <td>0.581035</td>\n",
       "      <td>0.839101</td>\n",
       "      <td>-0.362388</td>\n",
       "      <td>1.229239</td>\n",
       "      <td>-1.301037</td>\n",
       "      <td>-0.391490</td>\n",
       "      <td>0.330331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>-0.103114</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>-1.143757</td>\n",
       "      <td>0.051038</td>\n",
       "      <td>-0.425743</td>\n",
       "      <td>0.116079</td>\n",
       "      <td>-2.102412</td>\n",
       "      <td>-1.080850</td>\n",
       "      <td>-0.465172</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067677</td>\n",
       "      <td>-0.572875</td>\n",
       "      <td>1.130094</td>\n",
       "      <td>1.168141</td>\n",
       "      <td>-0.295463</td>\n",
       "      <td>-1.641248</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>2.436651</td>\n",
       "      <td>0.609978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>852</td>\n",
       "      <td>-0.506390</td>\n",
       "      <td>-0.095416</td>\n",
       "      <td>-0.082392</td>\n",
       "      <td>0.628147</td>\n",
       "      <td>-0.495957</td>\n",
       "      <td>-0.217843</td>\n",
       "      <td>-0.729260</td>\n",
       "      <td>-0.055025</td>\n",
       "      <td>1.161049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259313</td>\n",
       "      <td>-0.095036</td>\n",
       "      <td>0.595668</td>\n",
       "      <td>1.450615</td>\n",
       "      <td>-0.901555</td>\n",
       "      <td>-0.468974</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>-0.507186</td>\n",
       "      <td>-0.582950</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>853</td>\n",
       "      <td>-1.222850</td>\n",
       "      <td>0.406415</td>\n",
       "      <td>0.427107</td>\n",
       "      <td>0.388093</td>\n",
       "      <td>-0.631475</td>\n",
       "      <td>-0.223392</td>\n",
       "      <td>-0.995415</td>\n",
       "      <td>0.352018</td>\n",
       "      <td>1.150299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402418</td>\n",
       "      <td>-0.084839</td>\n",
       "      <td>1.354303</td>\n",
       "      <td>-1.412276</td>\n",
       "      <td>-0.598099</td>\n",
       "      <td>-2.042076</td>\n",
       "      <td>0.363272</td>\n",
       "      <td>-0.971272</td>\n",
       "      <td>-0.720224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>-0.784968</td>\n",
       "      <td>-0.026920</td>\n",
       "      <td>-0.332789</td>\n",
       "      <td>0.159759</td>\n",
       "      <td>-1.738487</td>\n",
       "      <td>-0.933227</td>\n",
       "      <td>-0.409914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.441070</td>\n",
       "      <td>-1.074331</td>\n",
       "      <td>-1.709144</td>\n",
       "      <td>0.333215</td>\n",
       "      <td>0.256185</td>\n",
       "      <td>-1.451273</td>\n",
       "      <td>1.051513</td>\n",
       "      <td>1.932738</td>\n",
       "      <td>0.274242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>853</td>\n",
       "      <td>0.625438</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>-0.784968</td>\n",
       "      <td>-0.026920</td>\n",
       "      <td>-0.332789</td>\n",
       "      <td>0.159759</td>\n",
       "      <td>-1.738487</td>\n",
       "      <td>-0.933227</td>\n",
       "      <td>-0.409914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.441070</td>\n",
       "      <td>-1.074331</td>\n",
       "      <td>-1.709144</td>\n",
       "      <td>0.333215</td>\n",
       "      <td>0.256185</td>\n",
       "      <td>-1.451273</td>\n",
       "      <td>1.051513</td>\n",
       "      <td>1.932738</td>\n",
       "      <td>0.274242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2562 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_id    target       f_0       f_1       f_2       f_3       f_4  \\\n",
       "0           0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1220        0 -0.300875  0.932573  0.113691 -0.402206  0.378386 -0.203938   \n",
       "2440        0 -0.231040  0.810802 -0.514115  0.742368 -0.616673 -0.194255   \n",
       "1           1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1221        1 -0.917045  0.373575  0.296349  0.019102 -0.031842 -0.222027   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "852       852 -0.103114  0.023042 -1.143757  0.051038 -0.425743  0.116079   \n",
       "3292      852 -0.506390 -0.095416 -0.082392  0.628147 -0.495957 -0.217843   \n",
       "3293      853 -1.222850  0.406415  0.427107  0.388093 -0.631475 -0.223392   \n",
       "2073      853  0.000000  0.125338 -0.784968 -0.026920 -0.332789  0.159759   \n",
       "853       853  0.625438  0.125338 -0.784968 -0.026920 -0.332789  0.159759   \n",
       "\n",
       "           f_5       f_6       f_7  ...     f_291     f_292     f_293  \\\n",
       "0     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1220 -0.413469  0.965623  1.230508  ... -1.095620  0.200075  0.819155   \n",
       "2440  1.771210  1.428127  1.134144  ...  0.912726 -0.734579  0.819155   \n",
       "1     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1221 -0.199950  1.325165  1.267433  ... -1.081652  0.645607  0.581035   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "852  -2.102412 -1.080850 -0.465172  ...  1.067677 -0.572875  1.130094   \n",
       "3292 -0.729260 -0.055025  1.161049  ...  0.259313 -0.095036  0.595668   \n",
       "3293 -0.995415  0.352018  1.150299  ... -0.402418 -0.084839  1.354303   \n",
       "2073 -1.738487 -0.933227 -0.409914  ... -0.441070 -1.074331 -1.709144   \n",
       "853  -1.738487 -0.933227 -0.409914  ... -0.441070 -1.074331 -1.709144   \n",
       "\n",
       "         f_294     f_295     f_296     f_297     f_298     f_299  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1220  0.941183 -0.086764 -1.087009 -1.044826 -0.287605  0.321566   \n",
       "2440  0.941183 -0.387617 -1.087009 -0.929529 -0.974060 -0.343624   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1221  0.839101 -0.362388  1.229239 -1.301037 -0.391490  0.330331   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "852   1.168141 -0.295463 -1.641248  0.754601  2.436651  0.609978   \n",
       "3292  1.450615 -0.901555 -0.468974  0.767649 -0.507186 -0.582950   \n",
       "3293 -1.412276 -0.598099 -2.042076  0.363272 -0.971272 -0.720224   \n",
       "2073  0.333215  0.256185 -1.451273  1.051513  1.932738  0.274242   \n",
       "853   0.333215  0.256185 -1.451273  1.051513  1.932738  0.274242   \n",
       "\n",
       "      investment_id  \n",
       "0                 0  \n",
       "1220              1  \n",
       "2440              2  \n",
       "1                 0  \n",
       "1221              1  \n",
       "...             ...  \n",
       "852               0  \n",
       "3292              2  \n",
       "3293              2  \n",
       "2073              1  \n",
       "853               0  \n",
       "\n",
       "[2562 rows x 303 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# load data\n",
    "# define dataset\n",
    "max_encoder_length = 6\n",
    "max_prediction_length = 1\n",
    "\n",
    "# create validation and training dataset\n",
    "batch_size = 128\n",
    "max_prediction_length = 3\n",
    "max_encoder_length = 24\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    group_ids=[\"investment_id\"],\n",
    "    target=\"target\",\n",
    "    time_idx=\"time_id\",\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    # static_reals=[],\n",
    "    time_varying_unknown_reals=['target'] + [f\"f_{i}\" for i in range(300)],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"investment_id\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet.from_dataset(train_dataset, df_train, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = val_dataset.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 226.9k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:24<00:00,  1.30it/s]Restoring states from the checkpoint path at /media/user/12TB1/HanLi/GitHub/CMU11785-project/src/notebooks/.lr_find_df57d85b-2c29-4cba-967c-9f66c859e3c7.ckpt\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:27<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.2454708915685031\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "tft_model = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft_model.size()/1e3:.1f}k\")\n",
    "\n",
    "\n",
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "* Note: use tensorboard to check the logs: run ```tensorboard --logdir=<logging_folder>```\n",
    "* To visualize tensorboard in Jupyter Notebook: \n",
    "    ```\n",
    "    %reload_ext tensorboard\n",
    "    %tensorboard --logdir=<logging_folder>\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /media/user/12TB1/HanLi/GitHub/CMU11785-project/logs/tft_test/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0     \n",
      "3  | prescalers                         | ModuleDict                      | 4.9 K \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.7 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 210 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 528   \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "226 K     Trainable params\n",
      "0         Non-trainable params\n",
      "226 K     Total params\n",
      "0.908     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 226.9k\n",
      "Epoch 4: 100%|██████████| 31/31 [02:29<00:00,  4.81s/it, loss=0.204, v_num=0, train_loss_step=0.175, val_loss=0.142, train_loss_epoch=0.203]  \n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "DIR_LOGS = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/logs' # Change this!\n",
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=os.path.join(DIR_LOGS, \"tft_test\"),\n",
    "    name=\"lightning_logs\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    gpus=1,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft_model = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft_model.size()/1e3:.1f}k\")\n",
    "\n",
    "# fit network\n",
    "trainer.fit(\n",
    "    tft_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 6863), started 0:03:16 ago. (Use '!kill 6863' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bd9c66b3ad3c2d6d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bd9c66b3ad3c2d6d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "# %tensorboard --logdir=os.path.join(DIR_LOGS, 'tft_test/lightning_logs/version_0/events.out.tfevents.1650348368.srg-gpu.48045.1')\n",
    "%tensorboard --logdir=/media/user/12TB1/HanLi/GitHub/CMU11785-project/logs/tft_test/lightning_logs/version_0/events.out.tfevents.1650348368.srg-gpu.48045.1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52c4a99fb36d68752ce25c6541fc636e9171dab977cfe863248a143161a3b436"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('11785_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
