{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rf4EqRIxzKxA"
   },
   "outputs": [],
   "source": [
    "# install some packages\n",
    "\n",
    "# for easy downloading from google drive\n",
    "!pip install gdown \n",
    "\n",
    "# for loading parquet\n",
    "!pip install pyarrow\n",
    "!pip install fastparquet\n",
    "\n",
    "# for models\n",
    "!pip install pytorch_lightning\n",
    "!pip install pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "poKYjLNFy6_M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as ttf\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQqb3QDtBMNO"
   },
   "source": [
    "# Download Data & Create Test DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PUhKvK7y6_N",
    "outputId": "a6160ed7-c69a-4b88-cf14-dbfddf488a77"
   },
   "outputs": [],
   "source": [
    "if False: # download unprocessed data in parquet form\n",
    "    !kaggle datasets download -d robikscube/ubiquant-parquet -p /home/ubuntu/data/ubiquant\n",
    "    !unzip -q /home/ubuntu/data/ubiquant/ubiquant-parquet.zip -d /home/ubuntu/data/ubiquant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    !gdown 1yhCV0v-GgYAfhKnJptvqSZdivvnAa27M -O /home/ubuntu/data/dyj_byid.zip\n",
    "    !unzip -q /home/ubuntu/data/dyj_byid.zip -d /home/ubuntu/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "86FXACpfJBKZ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/home/ubuntu/data/ubiquant/train_low_mem.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DY4mEadYJBNH",
    "outputId": "bde0ffc2-e75a-4ce3-d463-71aa02c04854"
   },
   "outputs": [],
   "source": [
    "#!gdown 1QBvxnH4Jb_wZ5lMf1ATSssEwo3UTQmQn -O /content/ubiquant/test_500_ids.pkl\n",
    "\n",
    "with open('/home/ubuntu/efs/project/src/data/test_500_ids.pkl', 'rb') as f:\n",
    "    test_500_ids = pickle.load(f)\n",
    "with open('/home/ubuntu/efs/project/src/data/test_1000_ids.pkl', 'rb') as f:\n",
    "    test_1000_ids = pickle.load(f)\n",
    "with open('/home/ubuntu/efs/project/src/data/50_test_ids.pkl', 'rb') as f:\n",
    "    test_50_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tK-0slWKuRwx"
   },
   "outputs": [],
   "source": [
    "test_df = df[(df['investment_id'].isin(test_50_ids)) & (df['time_id'] >= 1100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTrHFL5XuaWD",
    "outputId": "0d817da7-7319-4fcf-bbfd-01dceaa0e10f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id            object\n",
       "time_id            int64\n",
       "investment_id     object\n",
       "target           float32\n",
       "f_0              float32\n",
       "                  ...   \n",
       "f_295            float32\n",
       "f_296            float32\n",
       "f_297            float32\n",
       "f_298            float32\n",
       "f_299            float32\n",
       "Length: 304, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.investment_id = test_df.investment_id.astype(str)\n",
    "test_df.time_id = test_df.time_id.astype(int)\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRL6HwbaJBst"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "OJnb9b7wvUux"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_lightning.loggers import WandbLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEf4D5AOJBRu",
    "outputId": "1119e81f-b9ce-4a1f-dac9-35863a37b60f"
   },
   "outputs": [],
   "source": [
    "# Download Trained Model, DataSet and \n",
    "if False:\n",
    "    ! gdown --folder 1cVr_V6KOoSyL_Ry-PUOphRW74En1Rq04 -O /home/ubuntu/data/trained_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "rJMJhCxUu0Eq",
    "outputId": "39629890-1bc9-46c6-c55d-a4e4235e74d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train dataset completed\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TimeSeriesDataSet.load(\"/home/ubuntu/data/trained_model/TFT_429_tune_3/tft_train_100_samples.pf\")\n",
    "print(\"Load train dataset completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_model = TemporalFusionTransformer.load_from_checkpoint(\"/home/ubuntu/data/trained_model/TFT_429_tune_3/Linux_429_3_ckpt/429_3_epoch=10-val_loss=0.13-val_RMSE=0.69.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute-Force Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-Together Test: 3 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_3steps(model, test_df, train_dataset, metric = 'all'):\n",
    "    test_time_steps = test_df.time_id.unique()\n",
    "    \n",
    "    pred_0 = list()\n",
    "    pred_1 = list()\n",
    "    pred_2 = list()\n",
    "\n",
    "    target_0 = list()\n",
    "    target_1 = list()\n",
    "    target_2 = list()\n",
    "\n",
    "    errors = dict()\n",
    "    \n",
    "    for i in range(19, len(test_time_steps)):\n",
    "        test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_df[test_df['time_id'] <= test_time_steps[i]], predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
    "        test_dataloader = test_dataset.to_dataloader(train=False, batch_size=64, num_workers=4)\n",
    "        predictions, inputs = model.predict(test_dataloader, mode='prediction', return_x=True)\n",
    "        \n",
    "        pred = predictions.clone().detach()\n",
    "        targ = inputs['decoder_target'].clone().detach()\n",
    "\n",
    "        pred_0.append(pred[:,0])\n",
    "        pred_1.append(pred[:,1])\n",
    "        pred_2.append(pred[:,2])\n",
    "        target_0.append(targ[:,0])\n",
    "        target_1.append(targ[:,1])\n",
    "        target_2.append(targ[:,2])\n",
    "\n",
    "    if metric == 'Pearson' or metric == 'all':\n",
    "        y0 = torch.cat(pred_0).reshape(1,-1)\n",
    "        y1 = torch.cat(pred_1).reshape(1,-1)\n",
    "        y2 = torch.cat(pred_2).reshape(1,-1)\n",
    "        \n",
    "        t0 = torch.cat(target_0).reshape(1,-1)\n",
    "        t1 = torch.cat(target_1).reshape(1,-1)\n",
    "        t2 = torch.cat(target_2).reshape(1,-1)\n",
    "        \n",
    "        z0 = torch.cat((y0, t0), dim=0) # 2, B*T+\n",
    "        z1 = torch.cat((y1, t1), dim=0) # 2, B*T+\n",
    "        z2 = torch.cat((y2, t2), dim=0) # 2, B*T+\n",
    "        \n",
    "        pearson_0 = torch.corrcoef(z0)[0][1].item()\n",
    "        pearson_1 = torch.corrcoef(z1)[0][1].item()\n",
    "        pearson_2 = torch.corrcoef(z2)[0][1].item()\n",
    "        \n",
    "        errors['pearson_0'] = pearson_0\n",
    "        errors['pearson_1'] = pearson_1\n",
    "        errors['pearson_2'] = pearson_2\n",
    "        \n",
    "        print('1-step ahead Pearson correlation is')\n",
    "        print(pearson_0)\n",
    "\n",
    "        print('2-step ahead Pearson correlation is')\n",
    "        print(pearson_1)\n",
    "\n",
    "        print('3-step ahead Pearson correlation is')\n",
    "        print(pearson_2)\n",
    "\n",
    "    if metric == 'SMAPE' or metric == 'all':\n",
    "        y0 = torch.cat(pred_0).reshape(-1)\n",
    "        y1 = torch.cat(pred_1).reshape(-1)\n",
    "        y2 = torch.cat(pred_2).reshape(-1)\n",
    "        \n",
    "        t0 = torch.cat(target_0).reshape(-1)\n",
    "        t1 = torch.cat(target_1).reshape(-1)\n",
    "        t2 = torch.cat(target_2).reshape(-1)\n",
    "\n",
    "        smape_0 = torch.mean(2 * (y0 - t0).abs() / (y0.abs() + t0.abs() + 1e-8)).item()\n",
    "        smape_1 = torch.mean(2 * (y1 - t1).abs() / (y1.abs() + t1.abs() + 1e-8)).item()\n",
    "        smape_2 = torch.mean(2 * (y2 - t2).abs() / (y2.abs() + t2.abs() + 1e-8)).item()\n",
    "        \n",
    "        errors['smape_0'] = smape_0\n",
    "        errors['smape_1'] = smape_1\n",
    "        errors['smape_2'] = smape_2\n",
    "        \n",
    "        print('1-step ahead SMAPE is')\n",
    "        print(smape_0)\n",
    "\n",
    "        print('2-step ahead SMAPE is')\n",
    "        print(smape_1)\n",
    "\n",
    "        print('3-step ahead SMAPE is')\n",
    "        print(smape_2)\n",
    "\n",
    "    if metric == 'SMAPE' or metric == 'all':\n",
    "        y0 = torch.cat(pred_0).reshape(-1)\n",
    "        y1 = torch.cat(pred_1).reshape(-1)\n",
    "        y2 = torch.cat(pred_2).reshape(-1)\n",
    "        \n",
    "        t0 = torch.cat(target_0).reshape(-1)\n",
    "        t1 = torch.cat(target_1).reshape(-1)\n",
    "        t2 = torch.cat(target_2).reshape(-1)\n",
    "\n",
    "        rmse_0 = torch.sqrt(torch.mean(torch.pow(y0 - t0, 2))).item()\n",
    "        rmse_1 = torch.sqrt(torch.mean(torch.pow(y1 - t1, 2))).item()\n",
    "        rmse_2 = torch.sqrt(torch.mean(torch.pow(y2 - t2, 2))).item()\n",
    "        \n",
    "        errors['rmse_0'] = rmse_0\n",
    "        errors['rmse_1'] = rmse_1\n",
    "        errors['rmse_2'] = rmse_2\n",
    "        \n",
    "        print('1-step ahead RMSE is')\n",
    "        print(rmse_0)\n",
    "\n",
    "        print('2-step ahead RMSE is')\n",
    "        print(rmse_1)\n",
    "\n",
    "        print('3-step ahead RMSE is')\n",
    "        print(rmse_1)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-step ahead Pearson correlation is\n",
      "tensor(0.0050)\n",
      "2-step ahead Pearson correlation is\n",
      "tensor(0.0176)\n",
      "3-step ahead Pearson correlation is\n",
      "tensor(-0.0135)\n",
      "1-step ahead SMAPE is\n",
      "tensor(1.6089)\n",
      "2-step ahead SMAPE is\n",
      "tensor(1.6070)\n",
      "3-step ahead SMAPE is\n",
      "tensor(1.6164)\n",
      "1-step ahead RMSE is\n",
      "tensor(0.9130)\n",
      "2-step ahead RMSE is\n",
      "tensor(0.8662)\n",
      "3-step ahead RMSE is\n",
      "tensor(0.8662)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pearson_0': tensor(0.0050),\n",
       " 'pearson_1': tensor(0.0176),\n",
       " 'pearson_2': tensor(-0.0135),\n",
       " 'smape_0': tensor(1.6089),\n",
       " 'smape_1': tensor(1.6070),\n",
       " 'smape_2': tensor(1.6164),\n",
       " 'rmse_0': tensor(0.9130),\n",
       " 'rmse_1': tensor(0.8662),\n",
       " 'rmse_2': tensor(0.9254)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_3steps(model=tft_model, test_df=test_df, train_dataset=train_dataset, metric = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-Together Test: Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_3steps_quantiles(model, test_df, train_dataset):\n",
    "    \n",
    "    test_time_steps = test_df.time_id.unique()\n",
    "    \n",
    "    losses_0 = list()\n",
    "    losses_1 = list()\n",
    "    losses_2 = list()\n",
    "\n",
    "    errors = dict()\n",
    "    \n",
    "    quantiles = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "\n",
    "    for i in range(19, len(test_time_steps)):\n",
    "        test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_df[test_df['time_id'] <= test_time_steps[i]], predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
    "        test_dataloader = test_dataset.to_dataloader(train=False, batch_size=64, num_workers=4)\n",
    "        predictions, inputs = model.predict(test_dataloader, mode='quantiles', return_x=True)\n",
    "        \n",
    "        y_pred = predictions.clone().detach() # 50 * 3 * 7\n",
    "        target = inputs['decoder_target'].clone().detach() # 50 * 3\n",
    "\n",
    "        losses = list()\n",
    "        for i, q in enumerate(quantiles):\n",
    "            errors = target - y_pred[..., i]\n",
    "            losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(-1))\n",
    "        losses = torch.cat(losses, dim=2) # 50 * 3 * 7\n",
    "\n",
    "        losses_0.append(torch.mean(losses.clone().detach()[:,0,:]))\n",
    "        losses_1.append(torch.mean(losses.clone().detach()[:,1,:]))\n",
    "        losses_2.append(torch.mean(losses.clone().detach()[:,2,:]))\n",
    "        \n",
    "    loss_0 = torch.mean(torch.stack(losses_0)).item()\n",
    "    loss_1 = torch.mean(torch.stack(losses_1)).item()\n",
    "    loss_2 = torch.mean(torch.stack(losses_2)).item()\n",
    "\n",
    "    print(loss_0)\n",
    "\n",
    "    errors['quantile_0'] = loss_0\n",
    "    errors['quantile_1'] = loss_1\n",
    "    errors['quantile_2'] = loss_2\n",
    "\n",
    "    print('1-step ahead Quantile Loss is')\n",
    "    print(loss_0)\n",
    "\n",
    "    print('2-step ahead Quantile Loss is')\n",
    "    print(loss_1)\n",
    "\n",
    "    print('3-step ahead Quantile Loss is')\n",
    "    print(loss_2)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_3steps_quantiles(model=tft_model, test_df=test_df, train_dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Investment_id Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_3steps(model, test_df, train_dataset, metric = 'all'):\n",
    "    test_time_steps = test_df.time_id.unique()\n",
    "    \n",
    "    pred_0 = list()\n",
    "    pred_1 = list()\n",
    "    pred_2 = list()\n",
    "\n",
    "    target_0 = list()\n",
    "    target_1 = list()\n",
    "    target_2 = list()\n",
    "\n",
    "    errors = dict()\n",
    "    \n",
    "    for i in range(19, len(test_time_steps)):\n",
    "        test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_df[test_df['time_id'] <= test_time_steps[i]], predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
    "        test_dataloader = test_dataset.to_dataloader(train=False, batch_size=64, num_workers=4)\n",
    "        predictions, inputs = model.predict(test_dataloader, mode='prediction', return_x=True)\n",
    "        \n",
    "        pred = predictions.clone().detach()\n",
    "        targ = inputs['decoder_target'].clone().detach()\n",
    "\n",
    "        pred_0.append(pred[:,0])\n",
    "        pred_1.append(pred[:,1])\n",
    "        pred_2.append(pred[:,2])\n",
    "        target_0.append(targ[:,0])\n",
    "        target_1.append(targ[:,1])\n",
    "        target_2.append(targ[:,2])\n",
    "\n",
    "    if metric == 'Pearson' or metric == 'all':\n",
    "        y0 = torch.cat(pred_0).reshape(1,-1)\n",
    "        y1 = torch.cat(pred_1).reshape(1,-1)\n",
    "        y2 = torch.cat(pred_2).reshape(1,-1)\n",
    "        \n",
    "        t0 = torch.cat(target_0).reshape(1,-1)\n",
    "        t1 = torch.cat(target_1).reshape(1,-1)\n",
    "        t2 = torch.cat(target_2).reshape(1,-1)\n",
    "        \n",
    "        z0 = torch.cat((y0, t0), dim=0) # 2, B*T+\n",
    "        z1 = torch.cat((y1, t1), dim=0) # 2, B*T+\n",
    "        z2 = torch.cat((y2, t2), dim=0) # 2, B*T+\n",
    "        \n",
    "        pearson_0 = torch.corrcoef(z0)[0][1].item()\n",
    "        pearson_1 = torch.corrcoef(z1)[0][1].item()\n",
    "        pearson_2 = torch.corrcoef(z2)[0][1].item()\n",
    "        \n",
    "        errors['pearson_0'] = pearson_0\n",
    "        errors['pearson_1'] = pearson_1\n",
    "        errors['pearson_2'] = pearson_2\n",
    "        \n",
    "        print('1-step ahead Pearson correlation is')\n",
    "        print(pearson_0)\n",
    "\n",
    "        print('2-step ahead Pearson correlation is')\n",
    "        print(pearson_1)\n",
    "\n",
    "        print('3-step ahead Pearson correlation is')\n",
    "        print(pearson_2)\n",
    "\n",
    "    if metric == 'SMAPE' or metric == 'all':\n",
    "        y0 = torch.cat(pred_0).reshape(-1)\n",
    "        y1 = torch.cat(pred_1).reshape(-1)\n",
    "        y2 = torch.cat(pred_2).reshape(-1)\n",
    "        \n",
    "        t0 = torch.cat(target_0).reshape(-1)\n",
    "        t1 = torch.cat(target_1).reshape(-1)\n",
    "        t2 = torch.cat(target_2).reshape(-1)\n",
    "\n",
    "        smape_0 = torch.mean(2 * (y0 - t0).abs() / (y0.abs() + t0.abs() + 1e-8)).item()\n",
    "        smape_1 = torch.mean(2 * (y1 - t1).abs() / (y1.abs() + t1.abs() + 1e-8)).item()\n",
    "        smape_2 = torch.mean(2 * (y2 - t2).abs() / (y2.abs() + t2.abs() + 1e-8)).item()\n",
    "        \n",
    "        errors['smape_0'] = smape_0\n",
    "        errors['smape_1'] = smape_1\n",
    "        errors['smape_2'] = smape_2\n",
    "        \n",
    "        print('1-step ahead SMAPE is')\n",
    "        print(smape_0)\n",
    "\n",
    "        print('2-step ahead SMAPE is')\n",
    "        print(smape_1)\n",
    "\n",
    "        print('3-step ahead SMAPE is')\n",
    "        print(smape_2)\n",
    "\n",
    "    if metric == 'SMAPE' or metric == 'all':\n",
    "        y0 = torch.cat(pred_0).reshape(-1)\n",
    "        y1 = torch.cat(pred_1).reshape(-1)\n",
    "        y2 = torch.cat(pred_2).reshape(-1)\n",
    "        \n",
    "        t0 = torch.cat(target_0).reshape(-1)\n",
    "        t1 = torch.cat(target_1).reshape(-1)\n",
    "        t2 = torch.cat(target_2).reshape(-1)\n",
    "\n",
    "        rmse_0 = torch.sqrt(torch.mean(torch.pow(y0 - t0, 2))).item()\n",
    "        rmse_1 = torch.sqrt(torch.mean(torch.pow(y1 - t1, 2))).item()\n",
    "        rmse_2 = torch.sqrt(torch.mean(torch.pow(y2 - t2, 2))).item()\n",
    "        \n",
    "        errors['rmse_0'] = rmse_0\n",
    "        errors['rmse_1'] = rmse_1\n",
    "        errors['rmse_2'] = rmse_2\n",
    "        \n",
    "        print('1-step ahead RMSE is')\n",
    "        print(rmse_0)\n",
    "\n",
    "        print('2-step ahead RMSE is')\n",
    "        print(rmse_1)\n",
    "\n",
    "        print('3-step ahead RMSE is')\n",
    "        print(rmse_1)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['34', '35', '89', '306', '322', '466', '615', '728', '861', '1062',\n",
       "       '1106', '1113', '1117', '1151', '1281', '1288', '1438', '1444',\n",
       "       '1544', '1555', '1568', '1607', '1766', '1997', '2120', '2422',\n",
       "       '2560', '2572', '2599', '2635', '2785', '2877', '2921', '2987',\n",
       "       '3012', '3029', '3060', '3082', '3160', '3251', '3255', '3331',\n",
       "       '3352', '3441', '3492', '3634', '3644', '3690', '3702'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df['time_id'] <= test_time_steps[16]) & (test_df['time_id'] >= test_time_steps[16])].investment_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_steps = test_df.time_id.unique()\n",
    "\n",
    "pred_0 = list()\n",
    "pred_1 = list()\n",
    "pred_2 = list()\n",
    "\n",
    "target_0 = list()\n",
    "target_1 = list()\n",
    "target_2 = list()\n",
    "\n",
    "errors = dict()\n",
    "\n",
    "for i in range(19, len(test_time_steps)):\n",
    "    test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_df[test_df['time_id'] <= test_time_steps[i]], predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
    "    test_dataloader = test_dataset.to_dataloader(train=False, batch_size=64, num_workers=4)\n",
    "    predictions, inputs = tft_model.predict(test_dataloader, mode='prediction', return_x=True)\n",
    "\n",
    "    pred = predictions.clone().detach()\n",
    "    targ = inputs['decoder_target'].clone().detach()\n",
    "\n",
    "    pred_0.append(pred[:,0])\n",
    "    pred_1.append(pred[:,1])\n",
    "    pred_2.append(pred[:,2])\n",
    "    target_0.append(targ[:,0])\n",
    "    target_1.append(targ[:,1])\n",
    "    target_2.append(targ[:,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if metric == 'Pearson' or metric == 'all':\n",
    "    y0 = torch.cat(pred_0).reshape(1,-1)\n",
    "    y1 = torch.cat(pred_1).reshape(1,-1)\n",
    "    y2 = torch.cat(pred_2).reshape(1,-1)\n",
    "\n",
    "    t0 = torch.cat(target_0).reshape(1,-1)\n",
    "    t1 = torch.cat(target_1).reshape(1,-1)\n",
    "    t2 = torch.cat(target_2).reshape(1,-1)\n",
    "\n",
    "    z0 = torch.cat((y0, t0), dim=0) # 2, B*T+\n",
    "    z1 = torch.cat((y1, t1), dim=0) # 2, B*T+\n",
    "    z2 = torch.cat((y2, t2), dim=0) # 2, B*T+\n",
    "\n",
    "    pearson_0 = torch.corrcoef(z0)[0][1].item()\n",
    "    pearson_1 = torch.corrcoef(z1)[0][1].item()\n",
    "    pearson_2 = torch.corrcoef(z2)[0][1].item()\n",
    "\n",
    "    errors['pearson_0'] = pearson_0\n",
    "    errors['pearson_1'] = pearson_1\n",
    "    errors['pearson_2'] = pearson_2\n",
    "\n",
    "    print('1-step ahead Pearson correlation is')\n",
    "    print(pearson_0)\n",
    "\n",
    "    print('2-step ahead Pearson correlation is')\n",
    "    print(pearson_1)\n",
    "\n",
    "    print('3-step ahead Pearson correlation is')\n",
    "    print(pearson_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [50] at entry 0 and [49] at entry 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y0s \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [50] at entry 0 and [49] at entry 16"
     ]
    }
   ],
   "source": [
    "y0s = torch.stack(pred_0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_steps = test_df.time_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110,\n",
       "       1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121,\n",
       "       1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132,\n",
       "       1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143,\n",
       "       1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154,\n",
       "       1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165,\n",
       "       1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176,\n",
       "       1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,\n",
       "       1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198,\n",
       "       1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209,\n",
       "       1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0 = list()\n",
    "pred_1 = list()\n",
    "pred_2 = list()\n",
    "\n",
    "target_0 = list()\n",
    "target_1 = list()\n",
    "target_2 = list()\n",
    "\n",
    "for i in range(19, len(test_time_steps)):\n",
    "    test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_df[test_df['time_id'] <= test_time_steps[i]], predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
    "    test_dataloader = test_dataset.to_dataloader(train=False, batch_size=64, num_workers=4)\n",
    "    predictions, inputs = tft_model.predict(test_dataloader, mode='prediction', return_x=True)\n",
    "    pred = predictions.clone().detach()\n",
    "    targ = inputs['decoder_target'].clone().detach()\n",
    "    \n",
    "    pred_0.append(pred[:,0])\n",
    "    pred_1.append(pred[:,1])\n",
    "    pred_2.append(pred[:,2])\n",
    "    target_0.append(targ[:,0])\n",
    "    target_1.append(targ[:,1])\n",
    "    target_2.append(targ[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "print(pred_0[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = torch.cat(target_0).reshape(1,-1)\n",
    "t1 = torch.cat(target_1).reshape(1,-1)\n",
    "t2 = torch.cat(target_2).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_df[test_df['time_id'] <= test_time_steps[19]], predict=True, stop_randomization=True, allow_missing_timesteps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = test_dataset.to_dataloader(train=False, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, inputs = tft_model.predict(test_dataloader, mode='quantiles', return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3])\n"
     ]
    }
   ],
   "source": [
    "print(inputs['decoder_target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "50 100 7 mean \n",
    " \n",
    "50 100 7\n",
    "\n",
    "50 100 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0849)\n"
     ]
    }
   ],
   "source": [
    "y1 = predictions.reshape(1, -1)\n",
    "t1 = inputs['decoder_target'].reshape(1, -1)\n",
    "z = torch.cat((y1, t1), dim=0) # 2, B*T+\n",
    "error = torch.corrcoef(z)[0][1]\n",
    "\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.clone().detach()[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5036])\n",
      "torch.Size([5036])\n"
     ]
    }
   ],
   "source": [
    "print(y1.shape)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5036])\n"
     ]
    }
   ],
   "source": [
    "rmse_0 = torch.pow(y0 - t0, 2)\n",
    "print(rmse_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uiVLntZvyAl",
    "tags": []
   },
   "source": [
    "# Test 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# What's important here is that we set *predict=False*.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TimeSeriesDataSet\u001b[38;5;241m.\u001b[39mfrom_dataset(\u001b[43mtrain_dataset\u001b[49m, test_df, predict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stop_randomization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_missing_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# What's important here is that we set *predict=False*.\n",
    "test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_df, predict=False, stop_randomization=True, allow_missing_timesteps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = test_dataset.to_dataloader(train=False, batch_size=200, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in test_dataloader:\n",
    "#    tft_model.forward(x)\n",
    "    print(x)\n",
    "    break\n",
    "#tft_model.forward(test_dataloader, mode='prediction', return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = predictions[:, 0].reshape(1, -1)\n",
    "y1 = predictions[:, 1].reshape(1, -1)\n",
    "y2 = predictions[:, 2].reshape(1, -1)\n",
    "\n",
    "\n",
    "# replace all NaN with 0\n",
    "y0 = torch.nan_to_num(y0)\n",
    "y1 = torch.nan_to_num(y1)\n",
    "y2 = torch.nan_to_num(y2)\n",
    "\n",
    "\n",
    "\n",
    "t0 = inputs['decoder_target'][:, 0].reshape(1, -1)\n",
    "t1 = inputs['decoder_target'][:, 1].reshape(1, -1)\n",
    "t2 = inputs['decoder_target'][:, 2].reshape(1, -1)\n",
    "\n",
    "z0 = torch.cat((y0, t0), dim=0) # 2, B*T+\n",
    "z1 = torch.cat((y1, t1), dim=0) # 2, B*T+\n",
    "z2 = torch.cat((y2, t2), dim=0) # 2, B*T+\n",
    "\n",
    "error_0 = torch.corrcoef(z0)[0][1]\n",
    "error_1 = torch.corrcoef(z1)[0][1]\n",
    "error_2 = torch.corrcoef(z2)[0][1]\n",
    "\n",
    "\n",
    "print('1-step ahead prediction correlation is')\n",
    "print(error_0)\n",
    "      \n",
    "print('2-step ahead prediction correlation is')\n",
    "print(error_1)\n",
    "\n",
    "print('3-step ahead prediction correlation is')\n",
    "print(error_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W69PACpZvyKc",
    "tags": []
   },
   "source": [
    "# Test 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8WvXKQvv4dx"
   },
   "source": [
    "I use data with time_id >= 1000 for testing. \n",
    "It turns out that there are 120 different time_id's for test data. \n",
    "I divde them into 6 parts: 0-19, 0-39, 0-59, 0-79, 0-99, 0-119.\n",
    "Then run predictions on them.\n",
    "\n",
    "I use encoder length = 14, decoder length = 3. \n",
    "Per my understanding, the model will tune itself on previous data and then make predictions on the last 3 time steps for each investment id. \n",
    "For example, take 0-59. The model will tune itself on 0-42 (not sure about this, it seems that it does make use of these data, but I'm not sure how), encode 43-56, and predict 57-59.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czeJRVLZyHjP"
   },
   "source": [
    "#### Create Test DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBpy5DeXvvwq"
   },
   "outputs": [],
   "source": [
    "test_dfs = dict()\n",
    "for i in range(6):\n",
    "    test_dfs['test_df_' + str(i)] = test_df.head(math.floor(((i+1)/6) *len(test_df. index)))\n",
    "    \n",
    "print(test_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bOimJd6yJvB"
   },
   "source": [
    "## Test using correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTi9hcFdvvzY"
   },
   "outputs": [],
   "source": [
    "errors = list()\n",
    "\n",
    "for i in range(6):\n",
    "    # create test_dataset from test_dfs, with parameter from train_dataset\n",
    "    test_dataset = TimeSeriesDataSet.from_dataset(train_dataset, test_dfs['test_df_' + str(i)], predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
    "    test_dataloader = test_dataset.to_dataloader(train=False, batch_size=64, num_workers=4)\n",
    "\n",
    "    # make predictions\n",
    "    predictions, inputs = tft_model.predict(test_dataloader, mode='prediction', return_x=True)\n",
    "\n",
    "    # calculate correlation \n",
    "    y1 = predictions.reshape(1, -1)\n",
    "    t1 = inputs['decoder_target'].reshape(1, -1)\n",
    "    z = torch.cat((y1, t1), dim=0) # 2, B*T+\n",
    "    error = torch.corrcoef(z)[0][1]\n",
    "\n",
    "    errors.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWDG4wTdvv1y"
   },
   "outputs": [],
   "source": [
    "print(errors)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_tft_test_yao_colab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "52c4a99fb36d68752ce25c6541fc636e9171dab977cfe863248a143161a3b436"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
