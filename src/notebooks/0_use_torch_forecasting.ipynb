{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ff4a5-85ef-4544-986d-129911cea505",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fe198-8be1-4866-b2a2-6122ff6e9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d4e90-e690-4902-b592-257e9f6725ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "# import dataset, network to train and metric to optimize\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, QuantileLoss, DeepAR\n",
    "\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aeedb8-d8b3-4316-8b7f-516e388c471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    !kaggle datasets download -d robikscube/ubiquant-parquet -p /home/ubuntu/data\n",
    "    !unzip -q /home/ubuntu/data/ubiquant-parquet.zip -d /home/ubuntu/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145d759-207c-411a-a8f5-29a0984ad23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = '/home/ubuntu/data'\n",
    "data = pd.read_parquet(os.path.join(dir_train, 'train_low_mem.parquet'))\n",
    "\n",
    "# pytorch-forecasting has no built-in methods for dealing with large dataset\n",
    "# when dataset is large, memory will run out\n",
    "# we only use a small fragment of the data to familiarize us with the package\n",
    "# for manual dealing of large dataset\n",
    "# search 'large datasets' on this page: https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html\n",
    "data = data[data['time_id'] <= 200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ec4b5-6391-485a-8e57-bb8ec79e5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesDataSet requires that \n",
    "# we turn investment_id to str, time_id to int\n",
    "\n",
    "data.investment_id = data.investment_id.astype(str)\n",
    "data.time_id = data.time_id.astype(int)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9eefb-d63a-45de-94a0-3f577642a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_names of features, to \n",
    "f_cols = [f'f_{i}' for i in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443343b-9108-47cd-8f98-981434f6abfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a6666-e1bb-4760-8a2a-d66a6fdef2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 12\n",
    "max_prediction_length = 1\n",
    "training_cutoff = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce314a-40c8-49f5-90f9-14d0097d6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_id <= training_cutoff],\n",
    "    time_idx='time_id',  # column name of time of observation\n",
    "    target='target',  # column name of target to predict\n",
    "    group_ids=['investment_id'],  # column name(s) for timeseries IDs\n",
    "    max_encoder_length=max_encoder_length,  # how much history to use\n",
    "    max_prediction_length=max_prediction_length,  # how far to predict into future\n",
    "    # covariates static for a timeseries ID\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    # investment_id as categorical covariates that are known in the future for preddiction\n",
    "    time_varying_known_categoricals=['investment_id'],\n",
    "    # put in f_cols and time_id as real covariates that are known in the future for prediction\n",
    "    time_varying_known_reals = f_cols + ['time_id'],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[],\n",
    "    allow_missing_timesteps=True,\n",
    "    # having add_nan=True in Encoder allows us to predict unseen investments\n",
    "    categorical_encoders = {'__group_id__investment_id': NaNLabelEncoder(add_nan=True), 'investment_id': NaNLabelEncoder(add_nan=True)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2432d-2998-44f2-a263-cc71f2f0f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = training.to_dataloader(train=True, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba102f-10aa-4289-aed4-dab56ee4fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea17cbe-ef90-4aef-8243-0fd7b404acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True,\n",
    "    categorical_encoders = {'__group_id__investment_id': NaNLabelEncoder(add_nan=True), 'investment_id': NaNLabelEncoder(add_nan=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a83e1-8414-49c9-83d6-cb5022f9b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = validation.to_dataloader(train=False, batch_size=32 * 10, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552fabd-b916-4dce-ae70-27d35f57bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.save(\"training.pkl\")\n",
    "validation.save(\"validation.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e70186-af53-476c-95a6-f80f77a898c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "deepar = DeepAR.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "#    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "#    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "#    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
    "# run into error saying \n",
    "# AssertionError: target target has to be real\n",
    "# working on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337cd6d8",
   "metadata": {},
   "source": [
    "### Pytorch Forecasting (Han Li 2022-4-17 updates)\n",
    "* [Data Passing](https://pytorch-forecasting.readthedocs.io/en/stable/tutorials/building.html#passing-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dec111d-fd08-4ed8-8244-4d290135eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "\n",
    "# Used Yujie's cleaned version\n",
    "DIR_BYID = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/local_data/content/databyid'\n",
    "\n",
    "ls_all_invest_ids = sorted([int(fn.split('.')[0]) for fn in os.listdir(os.path.join(DIR_BYID, 'target'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b54a894d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "      <th>investment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>1215</td>\n",
       "      <td>0.968079</td>\n",
       "      <td>-1.554290</td>\n",
       "      <td>-0.838289</td>\n",
       "      <td>-2.424482</td>\n",
       "      <td>0.915358</td>\n",
       "      <td>0.222851</td>\n",
       "      <td>0.305951</td>\n",
       "      <td>-0.223640</td>\n",
       "      <td>-0.234155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.694756</td>\n",
       "      <td>-0.566056</td>\n",
       "      <td>-1.300175</td>\n",
       "      <td>-1.033787</td>\n",
       "      <td>0.228409</td>\n",
       "      <td>-0.082722</td>\n",
       "      <td>0.180542</td>\n",
       "      <td>0.319280</td>\n",
       "      <td>0.456568</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>1216</td>\n",
       "      <td>-0.514005</td>\n",
       "      <td>-4.977215</td>\n",
       "      <td>-0.494941</td>\n",
       "      <td>-2.558681</td>\n",
       "      <td>1.110870</td>\n",
       "      <td>0.228895</td>\n",
       "      <td>-0.377394</td>\n",
       "      <td>-0.378233</td>\n",
       "      <td>-0.229393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.368321</td>\n",
       "      <td>-1.107128</td>\n",
       "      <td>-1.161238</td>\n",
       "      <td>0.858016</td>\n",
       "      <td>1.042636</td>\n",
       "      <td>0.944268</td>\n",
       "      <td>0.940109</td>\n",
       "      <td>-0.645547</td>\n",
       "      <td>0.501274</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>1217</td>\n",
       "      <td>-0.207239</td>\n",
       "      <td>-3.204356</td>\n",
       "      <td>-0.023446</td>\n",
       "      <td>-1.407762</td>\n",
       "      <td>1.220369</td>\n",
       "      <td>0.237594</td>\n",
       "      <td>-0.714554</td>\n",
       "      <td>-0.571917</td>\n",
       "      <td>-0.201502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605606</td>\n",
       "      <td>-1.116755</td>\n",
       "      <td>-2.465713</td>\n",
       "      <td>0.675163</td>\n",
       "      <td>0.800786</td>\n",
       "      <td>1.959251</td>\n",
       "      <td>1.591608</td>\n",
       "      <td>-0.853658</td>\n",
       "      <td>0.463734</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>1218</td>\n",
       "      <td>0.318535</td>\n",
       "      <td>-2.848888</td>\n",
       "      <td>0.337431</td>\n",
       "      <td>-1.288697</td>\n",
       "      <td>1.025864</td>\n",
       "      <td>0.236846</td>\n",
       "      <td>-0.315953</td>\n",
       "      <td>-0.539815</td>\n",
       "      <td>-0.121384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819054</td>\n",
       "      <td>-0.266339</td>\n",
       "      <td>0.482149</td>\n",
       "      <td>0.967866</td>\n",
       "      <td>0.098972</td>\n",
       "      <td>-1.386759</td>\n",
       "      <td>-0.426667</td>\n",
       "      <td>0.430580</td>\n",
       "      <td>0.457497</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>1219</td>\n",
       "      <td>-0.060477</td>\n",
       "      <td>-2.249727</td>\n",
       "      <td>0.580445</td>\n",
       "      <td>-0.497117</td>\n",
       "      <td>1.009598</td>\n",
       "      <td>0.234179</td>\n",
       "      <td>-2.126438</td>\n",
       "      <td>-0.039451</td>\n",
       "      <td>-0.181319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811402</td>\n",
       "      <td>-1.168044</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>0.132988</td>\n",
       "      <td>-0.075548</td>\n",
       "      <td>-1.190996</td>\n",
       "      <td>1.102322</td>\n",
       "      <td>0.403788</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_id    target       f_0       f_1       f_2       f_3       f_4  \\\n",
       "0           0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1           1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2           2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3           3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4           4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "6095     1215  0.968079 -1.554290 -0.838289 -2.424482  0.915358  0.222851   \n",
       "6096     1216 -0.514005 -4.977215 -0.494941 -2.558681  1.110870  0.228895   \n",
       "6097     1217 -0.207239 -3.204356 -0.023446 -1.407762  1.220369  0.237594   \n",
       "6098     1218  0.318535 -2.848888  0.337431 -1.288697  1.025864  0.236846   \n",
       "6099     1219 -0.060477 -2.249727  0.580445 -0.497117  1.009598  0.234179   \n",
       "\n",
       "           f_5       f_6       f_7  ...     f_291     f_292     f_293  \\\n",
       "0     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6095  0.305951 -0.223640 -0.234155  ... -0.694756 -0.566056 -1.300175   \n",
       "6096 -0.377394 -0.378233 -0.229393  ...  1.368321 -1.107128 -1.161238   \n",
       "6097 -0.714554 -0.571917 -0.201502  ...  0.605606 -1.116755 -2.465713   \n",
       "6098 -0.315953 -0.539815 -0.121384  ... -0.819054 -0.266339  0.482149   \n",
       "6099 -2.126438 -0.039451 -0.181319  ...  0.811402 -1.168044  0.875537   \n",
       "\n",
       "         f_294     f_295     f_296     f_297     f_298     f_299  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "6095 -1.033787  0.228409 -0.082722  0.180542  0.319280  0.456568   \n",
       "6096  0.858016  1.042636  0.944268  0.940109 -0.645547  0.501274   \n",
       "6097  0.675163  0.800786  1.959251  1.591608 -0.853658  0.463734   \n",
       "6098  0.967866  0.098972 -1.386759 -0.426667  0.430580  0.457497   \n",
       "6099  0.421628  0.132988 -0.075548 -1.190996  1.102322  0.403788   \n",
       "\n",
       "      investment_id  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "6095              4  \n",
       "6096              4  \n",
       "6097              4  \n",
       "6098              4  \n",
       "6099              4  \n",
       "\n",
       "[6100 rows x 303 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_cols = [f\"f_{i}\" for i in range(300)]\n",
    "\n",
    "# Read a subset for testing\n",
    "n = 5\n",
    "ls_dfs = []\n",
    "for id in ls_all_invest_ids[:n]:\n",
    "    df_f_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'feats/{id}.npy')), columns=f_cols)\n",
    "    df_t_id = pd.DataFrame(np.load(os.path.join(DIR_BYID, f'target/{id}.npy')), columns=['target'])\n",
    "    df_f_id['investment_id'] = id\n",
    "    ls_dfs.append(pd.concat([df_t_id, df_f_id], axis=1))\n",
    "\n",
    "df = pd.concat(ls_dfs).reset_index().rename(columns={'index': 'time_id'})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f466ea3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_idx': 'time_id',\n",
       " 'target': 'target',\n",
       " 'group_ids': ['investment_id'],\n",
       " 'weight': None,\n",
       " 'max_encoder_length': 5,\n",
       " 'min_encoder_length': 5,\n",
       " 'min_prediction_idx': 0,\n",
       " 'min_prediction_length': 2,\n",
       " 'max_prediction_length': 2,\n",
       " 'static_categoricals': [],\n",
       " 'static_reals': [],\n",
       " 'time_varying_known_categoricals': [],\n",
       " 'time_varying_known_reals': [],\n",
       " 'time_varying_unknown_categoricals': [],\n",
       " 'time_varying_unknown_reals': ['f_0',\n",
       "  'f_1',\n",
       "  'f_2',\n",
       "  'f_3',\n",
       "  'f_4',\n",
       "  'f_5',\n",
       "  'f_6',\n",
       "  'f_7',\n",
       "  'f_8',\n",
       "  'f_9',\n",
       "  'f_10',\n",
       "  'f_11',\n",
       "  'f_12',\n",
       "  'f_13',\n",
       "  'f_14',\n",
       "  'f_15',\n",
       "  'f_16',\n",
       "  'f_17',\n",
       "  'f_18',\n",
       "  'f_19',\n",
       "  'f_20',\n",
       "  'f_21',\n",
       "  'f_22',\n",
       "  'f_23',\n",
       "  'f_24',\n",
       "  'f_25',\n",
       "  'f_26',\n",
       "  'f_27',\n",
       "  'f_28',\n",
       "  'f_29',\n",
       "  'f_30',\n",
       "  'f_31',\n",
       "  'f_32',\n",
       "  'f_33',\n",
       "  'f_34',\n",
       "  'f_35',\n",
       "  'f_36',\n",
       "  'f_37',\n",
       "  'f_38',\n",
       "  'f_39',\n",
       "  'f_40',\n",
       "  'f_41',\n",
       "  'f_42',\n",
       "  'f_43',\n",
       "  'f_44',\n",
       "  'f_45',\n",
       "  'f_46',\n",
       "  'f_47',\n",
       "  'f_48',\n",
       "  'f_49',\n",
       "  'f_50',\n",
       "  'f_51',\n",
       "  'f_52',\n",
       "  'f_53',\n",
       "  'f_54',\n",
       "  'f_55',\n",
       "  'f_56',\n",
       "  'f_57',\n",
       "  'f_58',\n",
       "  'f_59',\n",
       "  'f_60',\n",
       "  'f_61',\n",
       "  'f_62',\n",
       "  'f_63',\n",
       "  'f_64',\n",
       "  'f_65',\n",
       "  'f_66',\n",
       "  'f_67',\n",
       "  'f_68',\n",
       "  'f_69',\n",
       "  'f_70',\n",
       "  'f_71',\n",
       "  'f_72',\n",
       "  'f_73',\n",
       "  'f_74',\n",
       "  'f_75',\n",
       "  'f_76',\n",
       "  'f_77',\n",
       "  'f_78',\n",
       "  'f_79',\n",
       "  'f_80',\n",
       "  'f_81',\n",
       "  'f_82',\n",
       "  'f_83',\n",
       "  'f_84',\n",
       "  'f_85',\n",
       "  'f_86',\n",
       "  'f_87',\n",
       "  'f_88',\n",
       "  'f_89',\n",
       "  'f_90',\n",
       "  'f_91',\n",
       "  'f_92',\n",
       "  'f_93',\n",
       "  'f_94',\n",
       "  'f_95',\n",
       "  'f_96',\n",
       "  'f_97',\n",
       "  'f_98',\n",
       "  'f_99',\n",
       "  'f_100',\n",
       "  'f_101',\n",
       "  'f_102',\n",
       "  'f_103',\n",
       "  'f_104',\n",
       "  'f_105',\n",
       "  'f_106',\n",
       "  'f_107',\n",
       "  'f_108',\n",
       "  'f_109',\n",
       "  'f_110',\n",
       "  'f_111',\n",
       "  'f_112',\n",
       "  'f_113',\n",
       "  'f_114',\n",
       "  'f_115',\n",
       "  'f_116',\n",
       "  'f_117',\n",
       "  'f_118',\n",
       "  'f_119',\n",
       "  'f_120',\n",
       "  'f_121',\n",
       "  'f_122',\n",
       "  'f_123',\n",
       "  'f_124',\n",
       "  'f_125',\n",
       "  'f_126',\n",
       "  'f_127',\n",
       "  'f_128',\n",
       "  'f_129',\n",
       "  'f_130',\n",
       "  'f_131',\n",
       "  'f_132',\n",
       "  'f_133',\n",
       "  'f_134',\n",
       "  'f_135',\n",
       "  'f_136',\n",
       "  'f_137',\n",
       "  'f_138',\n",
       "  'f_139',\n",
       "  'f_140',\n",
       "  'f_141',\n",
       "  'f_142',\n",
       "  'f_143',\n",
       "  'f_144',\n",
       "  'f_145',\n",
       "  'f_146',\n",
       "  'f_147',\n",
       "  'f_148',\n",
       "  'f_149',\n",
       "  'f_150',\n",
       "  'f_151',\n",
       "  'f_152',\n",
       "  'f_153',\n",
       "  'f_154',\n",
       "  'f_155',\n",
       "  'f_156',\n",
       "  'f_157',\n",
       "  'f_158',\n",
       "  'f_159',\n",
       "  'f_160',\n",
       "  'f_161',\n",
       "  'f_162',\n",
       "  'f_163',\n",
       "  'f_164',\n",
       "  'f_165',\n",
       "  'f_166',\n",
       "  'f_167',\n",
       "  'f_168',\n",
       "  'f_169',\n",
       "  'f_170',\n",
       "  'f_171',\n",
       "  'f_172',\n",
       "  'f_173',\n",
       "  'f_174',\n",
       "  'f_175',\n",
       "  'f_176',\n",
       "  'f_177',\n",
       "  'f_178',\n",
       "  'f_179',\n",
       "  'f_180',\n",
       "  'f_181',\n",
       "  'f_182',\n",
       "  'f_183',\n",
       "  'f_184',\n",
       "  'f_185',\n",
       "  'f_186',\n",
       "  'f_187',\n",
       "  'f_188',\n",
       "  'f_189',\n",
       "  'f_190',\n",
       "  'f_191',\n",
       "  'f_192',\n",
       "  'f_193',\n",
       "  'f_194',\n",
       "  'f_195',\n",
       "  'f_196',\n",
       "  'f_197',\n",
       "  'f_198',\n",
       "  'f_199',\n",
       "  'f_200',\n",
       "  'f_201',\n",
       "  'f_202',\n",
       "  'f_203',\n",
       "  'f_204',\n",
       "  'f_205',\n",
       "  'f_206',\n",
       "  'f_207',\n",
       "  'f_208',\n",
       "  'f_209',\n",
       "  'f_210',\n",
       "  'f_211',\n",
       "  'f_212',\n",
       "  'f_213',\n",
       "  'f_214',\n",
       "  'f_215',\n",
       "  'f_216',\n",
       "  'f_217',\n",
       "  'f_218',\n",
       "  'f_219',\n",
       "  'f_220',\n",
       "  'f_221',\n",
       "  'f_222',\n",
       "  'f_223',\n",
       "  'f_224',\n",
       "  'f_225',\n",
       "  'f_226',\n",
       "  'f_227',\n",
       "  'f_228',\n",
       "  'f_229',\n",
       "  'f_230',\n",
       "  'f_231',\n",
       "  'f_232',\n",
       "  'f_233',\n",
       "  'f_234',\n",
       "  'f_235',\n",
       "  'f_236',\n",
       "  'f_237',\n",
       "  'f_238',\n",
       "  'f_239',\n",
       "  'f_240',\n",
       "  'f_241',\n",
       "  'f_242',\n",
       "  'f_243',\n",
       "  'f_244',\n",
       "  'f_245',\n",
       "  'f_246',\n",
       "  'f_247',\n",
       "  'f_248',\n",
       "  'f_249',\n",
       "  'f_250',\n",
       "  'f_251',\n",
       "  'f_252',\n",
       "  'f_253',\n",
       "  'f_254',\n",
       "  'f_255',\n",
       "  'f_256',\n",
       "  'f_257',\n",
       "  'f_258',\n",
       "  'f_259',\n",
       "  'f_260',\n",
       "  'f_261',\n",
       "  'f_262',\n",
       "  'f_263',\n",
       "  'f_264',\n",
       "  'f_265',\n",
       "  'f_266',\n",
       "  'f_267',\n",
       "  'f_268',\n",
       "  'f_269',\n",
       "  'f_270',\n",
       "  'f_271',\n",
       "  'f_272',\n",
       "  'f_273',\n",
       "  'f_274',\n",
       "  'f_275',\n",
       "  'f_276',\n",
       "  'f_277',\n",
       "  'f_278',\n",
       "  'f_279',\n",
       "  'f_280',\n",
       "  'f_281',\n",
       "  'f_282',\n",
       "  'f_283',\n",
       "  'f_284',\n",
       "  'f_285',\n",
       "  'f_286',\n",
       "  'f_287',\n",
       "  'f_288',\n",
       "  'f_289',\n",
       "  'f_290',\n",
       "  'f_291',\n",
       "  'f_292',\n",
       "  'f_293',\n",
       "  'f_294',\n",
       "  'f_295',\n",
       "  'f_296',\n",
       "  'f_297',\n",
       "  'f_298',\n",
       "  'f_299'],\n",
       " 'variable_groups': {},\n",
       " 'constant_fill_strategy': {},\n",
       " 'allow_missing_timesteps': False,\n",
       " 'lags': {},\n",
       " 'add_relative_time_idx': False,\n",
       " 'add_target_scales': False,\n",
       " 'add_encoder_length': False,\n",
       " 'target_normalizer': GroupNormalizer(),\n",
       " 'categorical_encoders': {'__group_id__investment_id': NaNLabelEncoder(),\n",
       "  'investment_id': NaNLabelEncoder()},\n",
       " 'scalers': {'f_0': StandardScaler(),\n",
       "  'f_1': StandardScaler(),\n",
       "  'f_2': StandardScaler(),\n",
       "  'f_3': StandardScaler(),\n",
       "  'f_4': StandardScaler(),\n",
       "  'f_5': StandardScaler(),\n",
       "  'f_6': StandardScaler(),\n",
       "  'f_7': StandardScaler(),\n",
       "  'f_8': StandardScaler(),\n",
       "  'f_9': StandardScaler(),\n",
       "  'f_10': StandardScaler(),\n",
       "  'f_11': StandardScaler(),\n",
       "  'f_12': StandardScaler(),\n",
       "  'f_13': StandardScaler(),\n",
       "  'f_14': StandardScaler(),\n",
       "  'f_15': StandardScaler(),\n",
       "  'f_16': StandardScaler(),\n",
       "  'f_17': StandardScaler(),\n",
       "  'f_18': StandardScaler(),\n",
       "  'f_19': StandardScaler(),\n",
       "  'f_20': StandardScaler(),\n",
       "  'f_21': StandardScaler(),\n",
       "  'f_22': StandardScaler(),\n",
       "  'f_23': StandardScaler(),\n",
       "  'f_24': StandardScaler(),\n",
       "  'f_25': StandardScaler(),\n",
       "  'f_26': StandardScaler(),\n",
       "  'f_27': StandardScaler(),\n",
       "  'f_28': StandardScaler(),\n",
       "  'f_29': StandardScaler(),\n",
       "  'f_30': StandardScaler(),\n",
       "  'f_31': StandardScaler(),\n",
       "  'f_32': StandardScaler(),\n",
       "  'f_33': StandardScaler(),\n",
       "  'f_34': StandardScaler(),\n",
       "  'f_35': StandardScaler(),\n",
       "  'f_36': StandardScaler(),\n",
       "  'f_37': StandardScaler(),\n",
       "  'f_38': StandardScaler(),\n",
       "  'f_39': StandardScaler(),\n",
       "  'f_40': StandardScaler(),\n",
       "  'f_41': StandardScaler(),\n",
       "  'f_42': StandardScaler(),\n",
       "  'f_43': StandardScaler(),\n",
       "  'f_44': StandardScaler(),\n",
       "  'f_45': StandardScaler(),\n",
       "  'f_46': StandardScaler(),\n",
       "  'f_47': StandardScaler(),\n",
       "  'f_48': StandardScaler(),\n",
       "  'f_49': StandardScaler(),\n",
       "  'f_50': StandardScaler(),\n",
       "  'f_51': StandardScaler(),\n",
       "  'f_52': StandardScaler(),\n",
       "  'f_53': StandardScaler(),\n",
       "  'f_54': StandardScaler(),\n",
       "  'f_55': StandardScaler(),\n",
       "  'f_56': StandardScaler(),\n",
       "  'f_57': StandardScaler(),\n",
       "  'f_58': StandardScaler(),\n",
       "  'f_59': StandardScaler(),\n",
       "  'f_60': StandardScaler(),\n",
       "  'f_61': StandardScaler(),\n",
       "  'f_62': StandardScaler(),\n",
       "  'f_63': StandardScaler(),\n",
       "  'f_64': StandardScaler(),\n",
       "  'f_65': StandardScaler(),\n",
       "  'f_66': StandardScaler(),\n",
       "  'f_67': StandardScaler(),\n",
       "  'f_68': StandardScaler(),\n",
       "  'f_69': StandardScaler(),\n",
       "  'f_70': StandardScaler(),\n",
       "  'f_71': StandardScaler(),\n",
       "  'f_72': StandardScaler(),\n",
       "  'f_73': StandardScaler(),\n",
       "  'f_74': StandardScaler(),\n",
       "  'f_75': StandardScaler(),\n",
       "  'f_76': StandardScaler(),\n",
       "  'f_77': StandardScaler(),\n",
       "  'f_78': StandardScaler(),\n",
       "  'f_79': StandardScaler(),\n",
       "  'f_80': StandardScaler(),\n",
       "  'f_81': StandardScaler(),\n",
       "  'f_82': StandardScaler(),\n",
       "  'f_83': StandardScaler(),\n",
       "  'f_84': StandardScaler(),\n",
       "  'f_85': StandardScaler(),\n",
       "  'f_86': StandardScaler(),\n",
       "  'f_87': StandardScaler(),\n",
       "  'f_88': StandardScaler(),\n",
       "  'f_89': StandardScaler(),\n",
       "  'f_90': StandardScaler(),\n",
       "  'f_91': StandardScaler(),\n",
       "  'f_92': StandardScaler(),\n",
       "  'f_93': StandardScaler(),\n",
       "  'f_94': StandardScaler(),\n",
       "  'f_95': StandardScaler(),\n",
       "  'f_96': StandardScaler(),\n",
       "  'f_97': StandardScaler(),\n",
       "  'f_98': StandardScaler(),\n",
       "  'f_99': StandardScaler(),\n",
       "  'f_100': StandardScaler(),\n",
       "  'f_101': StandardScaler(),\n",
       "  'f_102': StandardScaler(),\n",
       "  'f_103': StandardScaler(),\n",
       "  'f_104': StandardScaler(),\n",
       "  'f_105': StandardScaler(),\n",
       "  'f_106': StandardScaler(),\n",
       "  'f_107': StandardScaler(),\n",
       "  'f_108': StandardScaler(),\n",
       "  'f_109': StandardScaler(),\n",
       "  'f_110': StandardScaler(),\n",
       "  'f_111': StandardScaler(),\n",
       "  'f_112': StandardScaler(),\n",
       "  'f_113': StandardScaler(),\n",
       "  'f_114': StandardScaler(),\n",
       "  'f_115': StandardScaler(),\n",
       "  'f_116': StandardScaler(),\n",
       "  'f_117': StandardScaler(),\n",
       "  'f_118': StandardScaler(),\n",
       "  'f_119': StandardScaler(),\n",
       "  'f_120': StandardScaler(),\n",
       "  'f_121': StandardScaler(),\n",
       "  'f_122': StandardScaler(),\n",
       "  'f_123': StandardScaler(),\n",
       "  'f_124': StandardScaler(),\n",
       "  'f_125': StandardScaler(),\n",
       "  'f_126': StandardScaler(),\n",
       "  'f_127': StandardScaler(),\n",
       "  'f_128': StandardScaler(),\n",
       "  'f_129': StandardScaler(),\n",
       "  'f_130': StandardScaler(),\n",
       "  'f_131': StandardScaler(),\n",
       "  'f_132': StandardScaler(),\n",
       "  'f_133': StandardScaler(),\n",
       "  'f_134': StandardScaler(),\n",
       "  'f_135': StandardScaler(),\n",
       "  'f_136': StandardScaler(),\n",
       "  'f_137': StandardScaler(),\n",
       "  'f_138': StandardScaler(),\n",
       "  'f_139': StandardScaler(),\n",
       "  'f_140': StandardScaler(),\n",
       "  'f_141': StandardScaler(),\n",
       "  'f_142': StandardScaler(),\n",
       "  'f_143': StandardScaler(),\n",
       "  'f_144': StandardScaler(),\n",
       "  'f_145': StandardScaler(),\n",
       "  'f_146': StandardScaler(),\n",
       "  'f_147': StandardScaler(),\n",
       "  'f_148': StandardScaler(),\n",
       "  'f_149': StandardScaler(),\n",
       "  'f_150': StandardScaler(),\n",
       "  'f_151': StandardScaler(),\n",
       "  'f_152': StandardScaler(),\n",
       "  'f_153': StandardScaler(),\n",
       "  'f_154': StandardScaler(),\n",
       "  'f_155': StandardScaler(),\n",
       "  'f_156': StandardScaler(),\n",
       "  'f_157': StandardScaler(),\n",
       "  'f_158': StandardScaler(),\n",
       "  'f_159': StandardScaler(),\n",
       "  'f_160': StandardScaler(),\n",
       "  'f_161': StandardScaler(),\n",
       "  'f_162': StandardScaler(),\n",
       "  'f_163': StandardScaler(),\n",
       "  'f_164': StandardScaler(),\n",
       "  'f_165': StandardScaler(),\n",
       "  'f_166': StandardScaler(),\n",
       "  'f_167': StandardScaler(),\n",
       "  'f_168': StandardScaler(),\n",
       "  'f_169': StandardScaler(),\n",
       "  'f_170': StandardScaler(),\n",
       "  'f_171': StandardScaler(),\n",
       "  'f_172': StandardScaler(),\n",
       "  'f_173': StandardScaler(),\n",
       "  'f_174': StandardScaler(),\n",
       "  'f_175': StandardScaler(),\n",
       "  'f_176': StandardScaler(),\n",
       "  'f_177': StandardScaler(),\n",
       "  'f_178': StandardScaler(),\n",
       "  'f_179': StandardScaler(),\n",
       "  'f_180': StandardScaler(),\n",
       "  'f_181': StandardScaler(),\n",
       "  'f_182': StandardScaler(),\n",
       "  'f_183': StandardScaler(),\n",
       "  'f_184': StandardScaler(),\n",
       "  'f_185': StandardScaler(),\n",
       "  'f_186': StandardScaler(),\n",
       "  'f_187': StandardScaler(),\n",
       "  'f_188': StandardScaler(),\n",
       "  'f_189': StandardScaler(),\n",
       "  'f_190': StandardScaler(),\n",
       "  'f_191': StandardScaler(),\n",
       "  'f_192': StandardScaler(),\n",
       "  'f_193': StandardScaler(),\n",
       "  'f_194': StandardScaler(),\n",
       "  'f_195': StandardScaler(),\n",
       "  'f_196': StandardScaler(),\n",
       "  'f_197': StandardScaler(),\n",
       "  'f_198': StandardScaler(),\n",
       "  'f_199': StandardScaler(),\n",
       "  'f_200': StandardScaler(),\n",
       "  'f_201': StandardScaler(),\n",
       "  'f_202': StandardScaler(),\n",
       "  'f_203': StandardScaler(),\n",
       "  'f_204': StandardScaler(),\n",
       "  'f_205': StandardScaler(),\n",
       "  'f_206': StandardScaler(),\n",
       "  'f_207': StandardScaler(),\n",
       "  'f_208': StandardScaler(),\n",
       "  'f_209': StandardScaler(),\n",
       "  'f_210': StandardScaler(),\n",
       "  'f_211': StandardScaler(),\n",
       "  'f_212': StandardScaler(),\n",
       "  'f_213': StandardScaler(),\n",
       "  'f_214': StandardScaler(),\n",
       "  'f_215': StandardScaler(),\n",
       "  'f_216': StandardScaler(),\n",
       "  'f_217': StandardScaler(),\n",
       "  'f_218': StandardScaler(),\n",
       "  'f_219': StandardScaler(),\n",
       "  'f_220': StandardScaler(),\n",
       "  'f_221': StandardScaler(),\n",
       "  'f_222': StandardScaler(),\n",
       "  'f_223': StandardScaler(),\n",
       "  'f_224': StandardScaler(),\n",
       "  'f_225': StandardScaler(),\n",
       "  'f_226': StandardScaler(),\n",
       "  'f_227': StandardScaler(),\n",
       "  'f_228': StandardScaler(),\n",
       "  'f_229': StandardScaler(),\n",
       "  'f_230': StandardScaler(),\n",
       "  'f_231': StandardScaler(),\n",
       "  'f_232': StandardScaler(),\n",
       "  'f_233': StandardScaler(),\n",
       "  'f_234': StandardScaler(),\n",
       "  'f_235': StandardScaler(),\n",
       "  'f_236': StandardScaler(),\n",
       "  'f_237': StandardScaler(),\n",
       "  'f_238': StandardScaler(),\n",
       "  'f_239': StandardScaler(),\n",
       "  'f_240': StandardScaler(),\n",
       "  'f_241': StandardScaler(),\n",
       "  'f_242': StandardScaler(),\n",
       "  'f_243': StandardScaler(),\n",
       "  'f_244': StandardScaler(),\n",
       "  'f_245': StandardScaler(),\n",
       "  'f_246': StandardScaler(),\n",
       "  'f_247': StandardScaler(),\n",
       "  'f_248': StandardScaler(),\n",
       "  'f_249': StandardScaler(),\n",
       "  'f_250': StandardScaler(),\n",
       "  'f_251': StandardScaler(),\n",
       "  'f_252': StandardScaler(),\n",
       "  'f_253': StandardScaler(),\n",
       "  'f_254': StandardScaler(),\n",
       "  'f_255': StandardScaler(),\n",
       "  'f_256': StandardScaler(),\n",
       "  'f_257': StandardScaler(),\n",
       "  'f_258': StandardScaler(),\n",
       "  'f_259': StandardScaler(),\n",
       "  'f_260': StandardScaler(),\n",
       "  'f_261': StandardScaler(),\n",
       "  'f_262': StandardScaler(),\n",
       "  'f_263': StandardScaler(),\n",
       "  'f_264': StandardScaler(),\n",
       "  'f_265': StandardScaler(),\n",
       "  'f_266': StandardScaler(),\n",
       "  'f_267': StandardScaler(),\n",
       "  'f_268': StandardScaler(),\n",
       "  'f_269': StandardScaler(),\n",
       "  'f_270': StandardScaler(),\n",
       "  'f_271': StandardScaler(),\n",
       "  'f_272': StandardScaler(),\n",
       "  'f_273': StandardScaler(),\n",
       "  'f_274': StandardScaler(),\n",
       "  'f_275': StandardScaler(),\n",
       "  'f_276': StandardScaler(),\n",
       "  'f_277': StandardScaler(),\n",
       "  'f_278': StandardScaler(),\n",
       "  'f_279': StandardScaler(),\n",
       "  'f_280': StandardScaler(),\n",
       "  'f_281': StandardScaler(),\n",
       "  'f_282': StandardScaler(),\n",
       "  'f_283': StandardScaler(),\n",
       "  'f_284': StandardScaler(),\n",
       "  'f_285': StandardScaler(),\n",
       "  'f_286': StandardScaler(),\n",
       "  'f_287': StandardScaler(),\n",
       "  'f_288': StandardScaler(),\n",
       "  'f_289': StandardScaler(),\n",
       "  'f_290': StandardScaler(),\n",
       "  'f_291': StandardScaler(),\n",
       "  'f_292': StandardScaler(),\n",
       "  'f_293': StandardScaler(),\n",
       "  'f_294': StandardScaler(),\n",
       "  'f_295': StandardScaler(),\n",
       "  'f_296': StandardScaler(),\n",
       "  'f_297': StandardScaler(),\n",
       "  'f_298': StandardScaler(),\n",
       "  'f_299': StandardScaler()},\n",
       " 'randomize_length': None,\n",
       " 'predict_mode': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dataset from the pandas dataframe\n",
    "dataset = TimeSeriesDataSet(\n",
    "    df,\n",
    "    group_ids=[\"investment_id\"],\n",
    "    target=\"target\",\n",
    "    time_idx=\"time_id\",\n",
    "    min_encoder_length=5,\n",
    "    max_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    max_prediction_length=2,\n",
    "    time_varying_unknown_reals=[f\"f_{i}\" for i in range(300)],\n",
    ")\n",
    "\n",
    "dataset.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a551fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = {'encoder_cat': tensor([], size=(4, 5, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 0.8952,  1.1545,  1.4696,  ..., -0.2996, -1.6060,  5.2190],\n",
      "         [ 0.8705,  0.8604,  1.5183,  ..., -0.5999, -1.5334,  5.2132],\n",
      "         [ 0.9316,  0.2112,  1.5212,  ..., -0.6561, -1.3178,  1.6526],\n",
      "         [ 0.9680, -0.4409,  1.5621,  ..., -0.3906, -1.3156,  1.5707],\n",
      "         [ 1.0579, -0.9110,  1.5842,  ..., -0.1730, -1.2395,  1.4460]],\n",
      "\n",
      "        [[ 1.2796,  0.9712, -0.1817,  ...,  1.5526, -1.6673,  0.1927],\n",
      "         [ 1.1332,  0.7899, -0.2313,  ...,  1.1810,  1.3822,  0.6540],\n",
      "         [ 0.8378,  0.9057, -0.2258,  ..., -1.9277, -0.8170,  0.6802],\n",
      "         [ 0.7789,  1.1605,  0.0203,  ..., -0.4066,  1.2564,  1.3275],\n",
      "         [ 0.3965,  1.2627, -1.7200,  ..., -2.3754,  1.1802,  3.1274]],\n",
      "\n",
      "        [[-0.1336, -0.4002, -0.1538,  ...,  0.4063,  0.9587,  1.7518],\n",
      "         [ 0.0537, -0.3221,  0.1672,  ..., -0.1246, -1.1590,  1.7976],\n",
      "         [-0.1631,  0.0553,  0.2934,  ..., -0.5409, -1.3804,  1.8047],\n",
      "         [-0.5378,  0.3192,  0.5522,  ..., -0.4021, -1.3477,  1.5718],\n",
      "         [-2.7355,  0.4631,  0.6887,  ..., -0.8665, -1.5151,  1.5930]],\n",
      "\n",
      "        [[ 0.8106, -0.2664,  0.5177,  ...,  0.9434, -1.2013, -0.2081],\n",
      "         [ 0.6492, -0.1118,  0.5840,  ..., -0.4419, -1.2213,  0.2606],\n",
      "         [ 0.6889,  0.0605,  0.9887,  ..., -0.4482, -1.1979,  0.1859],\n",
      "         [ 0.6794, -0.0811,  0.7790,  ..., -0.4008, -1.3389,  0.1490],\n",
      "         [ 0.6926, -0.2590,  0.7989,  ...,  0.0525, -1.5079,  0.1190]]]), 'encoder_target': tensor([[-1.0512,  1.4431, -0.6233, -0.3896, -0.4364],\n",
      "        [-2.6298,  0.1784, -0.4488, -1.6677, -0.1008],\n",
      "        [ 0.1481, -0.3454, -0.5317,  0.0678, -1.0423],\n",
      "        [ 0.1907, -0.6955,  0.0928, -0.1392,  0.9467]]), 'encoder_lengths': tensor([5, 5, 5, 5]), 'decoder_cat': tensor([], size=(4, 2, 0), dtype=torch.int64), 'decoder_cont': tensor([[[ 1.1680, -1.1045,  1.6205,  ..., -0.3736, -1.2586,  0.4674],\n",
      "         [ 0.4070, -0.8483,  1.6010,  ...,  0.4029, -1.2289,  1.0631]],\n",
      "\n",
      "        [[-0.1263,  1.0388,  0.7214,  ..., -2.1259,  1.3233,  2.8678],\n",
      "         [ 0.4044,  1.2276,  1.4286,  ..., -1.7923,  1.3054,  1.4643]],\n",
      "\n",
      "        [[-6.5621,  0.6162,  0.5168,  ...,  1.0112, -1.4778,  1.4014],\n",
      "         [-2.2694,  0.5035,  0.9508,  ..., -1.1783, -1.4370,  1.3112]],\n",
      "\n",
      "        [[ 0.3479, -0.5223,  0.6107,  ...,  0.1764, -1.4305, -0.1937],\n",
      "         [ 1.0149, -0.6595, -0.0981,  ...,  1.8962,  0.0860, -0.2362]]]), 'decoder_target': tensor([[-0.1388,  2.1983],\n",
      "        [-0.9894,  0.6269],\n",
      "        [-0.2159,  0.7787],\n",
      "        [ 0.4742,  3.3532]]), 'decoder_lengths': tensor([2, 2, 2, 2]), 'decoder_time_idx': tensor([[125, 126],\n",
      "        [898, 899],\n",
      "        [259, 260],\n",
      "        [931, 932]]), 'groups': tensor([[3],\n",
      "        [4],\n",
      "        [3],\n",
      "        [4]]), 'target_scale': tensor([[-0.0033,  0.7785],\n",
      "        [-0.0033,  0.7785],\n",
      "        [-0.0033,  0.7785],\n",
      "        [-0.0033,  0.7785]])}\n",
      "\n",
      "y = (tensor([[-0.1388,  2.1983],\n",
      "        [-0.9894,  0.6269],\n",
      "        [-0.2159,  0.7787],\n",
      "        [ 0.4742,  3.3532]]), None)\n",
      "\n",
      "sizes of x =\n",
      "\tencoder_cat = torch.Size([4, 5, 0])\n",
      "\tencoder_cont = torch.Size([4, 5, 300])\n",
      "\tencoder_target = torch.Size([4, 5])\n",
      "\tencoder_lengths = torch.Size([4])\n",
      "\tdecoder_cat = torch.Size([4, 2, 0])\n",
      "\tdecoder_cont = torch.Size([4, 2, 300])\n",
      "\tdecoder_target = torch.Size([4, 2])\n",
      "\tdecoder_lengths = torch.Size([4])\n",
      "\tdecoder_time_idx = torch.Size([4, 2])\n",
      "\tgroups = torch.Size([4, 1])\n",
      "\ttarget_scale = torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to a dataloader\n",
    "dataloader = dataset.to_dataloader(batch_size=4)\n",
    "\n",
    "# and load the first batch\n",
    "x, y = next(iter(dataloader))\n",
    "print(\"x =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
