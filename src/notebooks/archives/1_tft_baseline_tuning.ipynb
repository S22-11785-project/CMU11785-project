{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try TemporalFusionTransformer\n",
    "* Read: https://towardsdatascience.com/temporal-fusion-transformer-a-primer-on-deep-forecasting-in-python-4eb37f3f3594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 11785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11785"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss, SMAPE, MAE, RMSE, MAPE\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "DIR_PROJECT = '/media/user/12TB1/HanLi/GitHub/CMU11785-project/'\n",
    "sys.path.append(os.path.join(DIR_PROJECT, 'src'))\n",
    "sys.path.append(os.path.join(DIR_PROJECT, 'utils'))\n",
    "\n",
    "from criterions import Pearson\n",
    "\n",
    "DIR_DATA = os.path.join(DIR_PROJECT, 'local_data')\n",
    "DIR_LOGS = os.path.join(DIR_PROJECT, 'logs')\n",
    "DIR_TRAINED = os.path.join(DIR_PROJECT, 'local_trained/20220428')\n",
    "NUM_WORKERS = 16 # Use 4 for AWS\n",
    "\n",
    "ARGS = args = {\n",
    "    # ------------------------------\n",
    "    # Basic config\n",
    "    'random_seed': 11785,\n",
    "    'n_samples': 1000,\n",
    "    'batch_size': 64,\n",
    "    'n_workers' : NUM_WORKERS,\n",
    "    'criterion': {\n",
    "        'quantile': QuantileLoss(),\n",
    "        'pearson': Pearson.Pearson(),   # Miao's implementation\n",
    "        'other': None,                  # TODO: check out other loss (e.g., MSE)\n",
    "    },\n",
    "    # ------------------------------\n",
    "    # Hyperparameters\n",
    "    'lr_s': 2e-1,\n",
    "    'hidden_size': 256,\n",
    "    'attention_head_size': 1,        # use multihead for large hidden size\n",
    "    'dropout': 0.1,\n",
    "    'hidden_continuous_size': 8,     # set to <= hidden_size\n",
    "    'output_size': 7,                # 7 quantiles for QuantileLoss by default\n",
    "    'reduce_on_plateau_patience': 4, # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    'gradient_clip_val': 0.1,\n",
    "    # ------------------------------\n",
    "    # Logging\n",
    "    'logging_metrics': [QuantileLoss(), SMAPE(), MAE(), RMSE(), MAPE()],\n",
    "    # 'logging_metrics': [SMAPE(), MAE(), RMSE(), MAPE()],\n",
    "    'log_interval': 5,               # log every n batches, set to None when try to find best lr\n",
    "    'wandb_entity': '11785_project',\n",
    "    'wandb_project': '11785_pf_test',\n",
    "    'wandb_name': 'test_run_1',\n",
    "}\n",
    "seed_everything(ARGS['random_seed'], workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing dataset completed.\n"
     ]
    }
   ],
   "source": [
    "# load data, create validation and training dataset\n",
    "dir_pf_dataset = os.path.join(DIR_DATA, 'pf_dataset_tft')\n",
    "n = args['n_samples']\n",
    "\n",
    "train_dataset = TimeSeriesDataSet.load(os.path.join(dir_pf_dataset, f'pf_train_{n}_samples.pf'))\n",
    "val_dataset = TimeSeriesDataSet.load(os.path.join(dir_pf_dataset, f'pf_val_{n}_samples.pf'))\n",
    "test_dataset = TimeSeriesDataSet.load(os.path.join(dir_pf_dataset, f'pf_test_{n}_samples.pf'))\n",
    "\n",
    "# create dataloaders for model\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=args['batch_size'], num_workers=args['n_workers'])\n",
    "val_dataloader = val_dataset.to_dataloader(train=False, batch_size=args['batch_size'], num_workers=args['n_workers'])\n",
    "test_dataloader = test_dataset.to_dataloader(train=False, batch_size=args['batch_size'], num_workers=args['n_workers'])\n",
    "\n",
    "print(\"Load existing dataset completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    trial_args = copy.deepcopy(ARGS)\n",
    "\n",
    "    # load data, create validation and training dataset\n",
    "    dir_pf_dataset = os.path.join(DIR_DATA, 'pf_dataset_tft')\n",
    "    args['n_training_samples'] = n = trial.suggest_int('n_training_samples', 500, 1000, 500) # Treat amount of training samples as a hyperparameter\n",
    "\n",
    "    train_dataset = TimeSeriesDataSet.load(os.path.join(dir_pf_dataset, f'pf_train_{n}_samples.pf'))\n",
    "    val_dataset = TimeSeriesDataSet.load(os.path.join(dir_pf_dataset, f'pf_val_500_samples.pf')) # NOTE: Use 500 samples for validation and testing\n",
    "    # create dataloaders for model\n",
    "    train_dataloader = train_dataset.to_dataloader(train=True, batch_size=trial_args['batch_size'], num_workers=trial_args['n_workers'])\n",
    "    val_dataloader = val_dataset.to_dataloader(train=False, batch_size=trial_args['batch_size'], num_workers=trial_args['n_workers'])\n",
    "\n",
    "    lr = trial.suggest_loguniform('init_lr', 1e-4, 1e-1)\n",
    "    lstm_layers = trial.suggest_int('lstm_layers', 1, 3, 1)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 128, 768, 128)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.4, step=0.1)\n",
    "    attention_head_size = trial.suggest_int('attention_head_size', 1, 4, 1)\n",
    "    hidden_continuous_size = trial.suggest_int('hidden_continuous_size', 4, 16, 4)\n",
    "\n",
    "    print(f'Trial {trial.number}'.center(50, \"_\"))\n",
    "    print(\"==>> n: \", n)\n",
    "    print(\"==>> lr: \", lr)\n",
    "    print(\"==>> lstm_layers: \", lstm_layers)\n",
    "    print(\"==>> hidden_size: \", hidden_size)\n",
    "    print(\"==>> dropout: \", dropout)\n",
    "    print(\"==>> attention_head_size: \", attention_head_size)\n",
    "    print(\"==>> hidden_continuous_size: \", hidden_continuous_size)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "    lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "\n",
    "    # For saving model\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss', # val_SMAPE\n",
    "        dirpath=os.path.join(DIR_LOGS, f'trial_{trial.number}_ckpt'), \n",
    "        save_top_k=2, \n",
    "        filename=f'trial_{trial.number}_'+'{epoch:02d}-{val_loss:.2f}-{val_RMSE:.2f}'\n",
    "    )\n",
    "\n",
    "    logger = WandbLogger(\n",
    "        log_model=True,\n",
    "        entity=\"11785_project\",\n",
    "        project=\"11785_project_tuning_427\",\n",
    "        name=f'TFT_quantile_loss_tune_{trial.number}',\n",
    "        reinit=True\n",
    "    )\n",
    "    # wb_run = wandb.init(\n",
    "    #     entity=\"11785_project\",\n",
    "    #     project=\"11785_project_tuning\",\n",
    "    #     name=f'TFT_quantile_loss_tune_{trial.number}',\n",
    "    #     reinit=True,\n",
    "    # )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=30,\n",
    "        gpus=1,\n",
    "        weights_summary=\"top\",\n",
    "        gradient_clip_val=0.1,\n",
    "        limit_train_batches=0.1,  # use 10% fo batches for training for fast tuning\n",
    "        # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "        callbacks=[lr_logger, early_stop_callback, checkpoint_callback],\n",
    "        logger=logger,\n",
    "    )\n",
    "    trainer.logger.log_hyperparams(trial_args)\n",
    "\n",
    "    tft_model = TemporalFusionTransformer.from_dataset(\n",
    "        train_dataset,\n",
    "        learning_rate=lr,\n",
    "        lstm_layers=lstm_layers,\n",
    "        hidden_size=hidden_size,  # most important hyperparameter apart from learning rate\n",
    "        attention_head_size=attention_head_size, # number of attention heads. Set to up to 4 for large datasets\n",
    "        dropout=dropout,  # between 0.1 and 0.3 are good values\n",
    "        hidden_continuous_size=hidden_continuous_size,\n",
    "        output_size=args['output_size'],\n",
    "        loss=args['criterion']['quantile'],\n",
    "        # loss=args['criterion']['pearson'],\n",
    "        log_interval=args['log_interval'],  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "        reduce_on_plateau_patience=args['reduce_on_plateau_patience'], # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    )\n",
    "\n",
    "    # fit network\n",
    "    trainer.fit(tft_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    # wb_run.finish()\n",
    "    wandb.finish()\n",
    "    torch.save(tft_model.state_dict(), os.path.join(DIR_TRAINED, f'tft_tuning_{trial.number}.pth'))\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=60, n_jobs=1)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_results = trainer.test(tft_model, dataloaders=test_dataloader)\n",
    "\n",
    "\n",
    "# 1 2 3 4 5 | 6 7 8\n",
    "# 2 3 4 5 6 | 7 8 9\n",
    "\n",
    "3 * 7\n",
    "# MSE, Quantile, PearsonR\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52c4a99fb36d68752ce25c6541fc636e9171dab977cfe863248a143161a3b436"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('11785_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
